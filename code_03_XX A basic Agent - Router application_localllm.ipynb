{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee5c0c82-a3ff-4fe1-9238-69bba6c2bed7",
   "metadata": {},
   "source": [
    "### 03.03. Setting up Indexes"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8fa44f3-cd5c-4fcd-8a40-fe8046005824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T03:40:30.884891Z",
     "start_time": "2025-06-19T03:39:55.543751Z"
    }
   },
   "source": [
    "#Install prerequisite packages\n",
    "!pip install python-dotenv==1.0.0\n",
    "\n",
    "!pip install llama-index==0.10.59\n",
    "!pip install llama-index-llms-openai==0.1.27\n",
    "!pip install llama-index-embeddings-openai==0.1.11\n",
    "!pip install llama-index-llms-azure-openai==0.1.10\n",
    "!pip install llama-index-embeddings-azure-openai==0.1.11\n",
    "\n",
    "!pip install llama-index-llms-openai-like\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install sentence-transformers\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv==1.0.0 in ./.venv/lib/python3.12/site-packages (1.0.0)\r\n",
      "Requirement already satisfied: llama-index==0.10.59 in ./.venv/lib/python3.12/site-packages (0.10.59)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.2.9)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.13)\r\n",
      "Requirement already satisfied: llama-index-core==0.10.59 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.10.59)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.2.7)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.9.48.post4)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.27 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.27)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.9)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.7)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.33)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in ./.venv/lib/python3.12/site-packages (from llama-index==0.10.59) (0.1.6)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index==0.10.59) (2.0.41)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (3.12.13)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (2025.5.1)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (0.28.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (3.5)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (3.9.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.88.0)\r\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (2.3.0)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (11.2.1)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (2.32.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (4.14.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core==0.10.59->llama-index==0.10.59) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (1.20.1)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59) (4.13.4)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59) (4.3.1)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./.venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59) (0.0.26)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.59) (2.7)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index==0.10.59) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index==0.10.59) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.59->llama-index==0.10.59) (2024.11.6)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.59->llama-index==0.10.59) (3.10)\r\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in ./.venv/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (0.1.26)\r\n",
      "Requirement already satisfied: certifi>=2024.7.4 in ./.venv/lib/python3.12/site-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (2025.6.15)\r\n",
      "Requirement already satisfied: pydantic>=1.10 in ./.venv/lib/python3.12/site-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (2.11.7)\r\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index==0.10.59) (4.9.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core==0.10.59->llama-index==0.10.59) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.59->llama-index==0.10.59) (0.16.0)\r\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in ./.venv/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index==0.10.59) (0.4.9)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index==0.10.59) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.3.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index==0.10.59) (0.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama-index==0.10.59) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core==0.10.59->llama-index==0.10.59) (2.5.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.59->llama-index==0.10.59) (3.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.59->llama-index==0.10.59) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core==0.10.59->llama-index==0.10.59) (3.26.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.59->llama-index==0.10.59) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index==0.10.59) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index==0.10.59) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core==0.10.59->llama-index==0.10.59) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.59->llama-index==0.10.59) (1.17.0)\r\n",
      "Requirement already satisfied: llama-index-llms-openai==0.1.27 in ./.venv/lib/python3.12/site-packages (0.1.27)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.57 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-openai==0.1.27) (0.10.59)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.0.41)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.12.13)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2025.5.1)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.28.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.5)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.9.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.88.0)\r\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.3.0)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (11.2.1)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.32.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (4.14.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.20.1)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2024.11.6)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.10)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.10.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.11.7)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2025.6.15)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (0.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.5.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (3.26.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai==0.1.27) (1.17.0)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai==0.1.11 in ./.venv/lib/python3.12/site-packages (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.venv/lib/python3.12/site-packages (from llama-index-embeddings-openai==0.1.11) (0.10.59)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.0.41)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.12.13)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2025.5.1)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.28.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.5)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.9.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.88.0)\r\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.3.0)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (11.2.1)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.32.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (4.14.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.20.1)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2024.11.6)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.10)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.10.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.11.7)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.3.1)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2025.6.15)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (0.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.5.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (3.26.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.11) (1.17.0)\r\n",
      "Requirement already satisfied: llama-index-llms-azure-openai==0.1.10 in ./.venv/lib/python3.12/site-packages (0.1.10)\r\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-azure-openai==0.1.10) (1.23.0)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-llms-azure-openai==0.1.10) (0.28.1)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-azure-openai==0.1.10) (0.10.59)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-azure-openai==0.1.10) (0.1.27)\r\n",
      "Requirement already satisfied: azure-core>=1.31.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.34.0)\r\n",
      "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (45.0.4)\r\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.32.3)\r\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (4.14.0)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.0.41)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.12.13)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2025.5.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.5)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.9.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.88.0)\r\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.3.0)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (11.2.1)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.32.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (4.67.1)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.20.1)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2024.11.6)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.10)\r\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.17.0)\r\n",
      "Requirement already satisfied: cffi>=1.14 in ./.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (2.22)\r\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai==0.1.10) (2.10.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2025.6.15)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.10.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.11.7)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.3.1)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-llms-azure-openai==0.1.10) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai==0.1.10) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (0.4.1)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (3.26.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai==0.1.10) (2025.2)\r\n",
      "Requirement already satisfied: llama-index-embeddings-azure-openai==0.1.11 in ./.venv/lib/python3.12/site-packages (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in ./.venv/lib/python3.12/site-packages (from llama-index-embeddings-azure-openai==0.1.11) (0.10.59)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.3 in ./.venv/lib/python3.12/site-packages (from llama-index-embeddings-azure-openai==0.1.11) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-llms-azure-openai<0.2.0,>=0.1.3 in ./.venv/lib/python3.12/site-packages (from llama-index-embeddings-azure-openai==0.1.11) (0.1.10)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (6.0.2)\r\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.0.41)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.12.13)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.0.8)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2025.5.1)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.28.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.5)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.9.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.26.4)\r\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.88.0)\r\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.3.0)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (11.2.1)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.32.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (4.14.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.20.1)\r\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.23.0)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (0.1.27)\r\n",
      "Requirement already satisfied: azure-core>=1.31.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.34.0)\r\n",
      "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (45.0.4)\r\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.32.3)\r\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.3.1)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2024.11.6)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.10)\r\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.17.0)\r\n",
      "Requirement already satisfied: cffi>=1.14 in ./.venv/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (2.22)\r\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai==0.1.11) (2.10.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2025.6.15)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.10.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.11.7)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.3.1)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (0.4.1)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (3.26.1)\r\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (25.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-azure-openai==0.1.11) (2025.2)\r\n",
      "Collecting llama-index-llms-openai-like\r\n",
      "  Downloading llama_index_llms_openai_like-0.4.0-py3-none-any.whl.metadata (1.1 kB)\r\n",
      "Collecting llama-index-core<0.13,>=0.12.0 (from llama-index-llms-openai-like)\r\n",
      "  Downloading llama_index_core-0.12.43-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index-llms-openai-like)\r\n",
      "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting transformers<5,>=4.37.0 (from llama-index-llms-openai-like)\r\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.12.13)\r\n",
      "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\r\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.0.8)\r\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2025.5.1)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.28.1)\r\n",
      "Collecting llama-index-workflows>=0.2.1 (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Downloading llama_index_workflows-0.2.1-py3-none-any.whl.metadata (276 bytes)\r\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.5)\r\n",
      "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.9.1)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (11.2.1)\r\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.11.7)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.32.4)\r\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (80.9.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.0.41)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (4.14.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.20.1)\r\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.1.6)\r\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (4.3.8)\r\n",
      "Requirement already satisfied: openai<2,>=1.81.0 in ./.venv/lib/python3.12/site-packages (from llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (1.88.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (4.9.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (1.9.0)\r\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (0.10.0)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-openai-like) (3.10)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2025.6.15)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.16.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (0.4.1)\r\n",
      "Collecting filelock (from transformers<5,>=4.37.0->llama-index-llms-openai-like)\r\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers<5,>=4.37.0->llama-index-llms-openai-like)\r\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (25.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like) (2024.11.6)\r\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5,>=4.37.0->llama-index-llms-openai-like)\r\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting safetensors>=0.4.3 (from transformers<5,>=4.37.0->llama-index-llms-openai-like)\r\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers<5,>=4.37.0->llama-index-llms-openai-like)\r\n",
      "  Downloading hf_xet-1.1.4-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\r\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows>=0.2.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Downloading llama_index_instrumentation-0.1.0-py3-none-any.whl.metadata (252 bytes)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.5.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (2.5.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.2.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.26.1)\r\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like)\r\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-openai-like) (3.0.2)\r\n",
      "Downloading llama_index_llms_openai_like-0.4.0-py3-none-any.whl (4.6 kB)\r\n",
      "Downloading llama_index_core-0.12.43-py3-none-any.whl (7.6 MB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m7.6/7.6 MB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading banks-2.1.2-py3-none-any.whl (28 kB)\r\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\r\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m10.5/10.5 MB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\r\n",
      "Downloading hf_xet-1.1.4-cp37-abi3-macosx_11_0_arm64.whl (2.5 MB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading llama_index_workflows-0.2.1-py3-none-any.whl (29 kB)\r\n",
      "Downloading llama_index_instrumentation-0.1.0-py3-none-any.whl (14 kB)\r\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\r\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\r\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\r\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: filetype, safetensors, hf-xet, filelock, colorama, aiosqlite, huggingface-hub, griffe, tokenizers, llama-index-instrumentation, banks, transformers, llama-index-workflows, llama-index-core, llama-index-llms-openai, llama-index-llms-openai-like\r\n",
      "\u001B[2K  Attempting uninstall: llama-index-core[91m\u001B[0m\u001B[90m\u001B[0m \u001B[32m11/16\u001B[0m [transformers]ub]\r\n",
      "\u001B[2K    Found existing installation: llama-index-core 0.10.59\u001B[0m \u001B[32m11/16\u001B[0m [transformers]\r\n",
      "\u001B[2K    Uninstalling llama-index-core-0.10.59:[0m\u001B[90m\u001B[0m \u001B[32m11/16\u001B[0m [transformers]\r\n",
      "\u001B[2K      Successfully uninstalled llama-index-core-0.10.59\u001B[0m \u001B[32m11/16\u001B[0m [transformers]\r\n",
      "\u001B[2K  Attempting uninstall: llama-index-llms-openai1m\u001B[0m\u001B[90m\u001B[0m \u001B[32m13/16\u001B[0m [llama-index-core]\r\n",
      "\u001B[2K    Found existing installation: llama-index-llms-openai 0.1.27[0m \u001B[32m13/16\u001B[0m [llama-index-core]\r\n",
      "\u001B[2K    Uninstalling llama-index-llms-openai-0.1.27:0m\u001B[90m\u001B[0m \u001B[32m13/16\u001B[0m [llama-index-core]\r\n",
      "\u001B[2K      Successfully uninstalled llama-index-llms-openai-0.1.27\u001B[0m \u001B[32m13/16\u001B[0m [llama-index-core]\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m16/16\u001B[0m [llama-index-llms-openai-like]e]\r\n",
      "\u001B[1A\u001B[2K\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "llama-index-llms-azure-openai 0.1.10 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-llms-azure-openai 0.1.10 requires llama-index-llms-openai<0.2.0,>=0.1.1, but you have llama-index-llms-openai 0.4.7 which is incompatible.\r\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-indices-managed-llama-cloud 0.2.7 requires llama-index-core<0.11.0,>=0.10.48.post1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-cli 0.1.13 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-cli 0.1.13 requires llama-index-llms-openai<0.2.0,>=0.1.1, but you have llama-index-llms-openai 0.4.7 which is incompatible.\r\n",
      "llama-index-embeddings-azure-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-llms-openai<0.2.0,>=0.1.1, but you have llama-index-llms-openai 0.4.7 which is incompatible.\r\n",
      "llama-index-readers-llama-parse 0.1.6 requires llama-index-core<0.11.0,>=0.10.7, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index 0.10.59 requires llama-index-core==0.10.59, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index 0.10.59 requires llama-index-llms-openai<0.2.0,>=0.1.27, but you have llama-index-llms-openai 0.4.7 which is incompatible.\r\n",
      "llama-index-embeddings-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-agent-openai 0.2.9 requires llama-index-core<0.11.0,>=0.10.41, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-agent-openai 0.2.9 requires llama-index-llms-openai<0.2.0,>=0.1.5, but you have llama-index-llms-openai 0.4.7 which is incompatible.\r\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.12.43 which is incompatible.\r\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-llms-openai<0.2.0,>=0.1.1, but you have llama-index-llms-openai 0.4.7 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed aiosqlite-0.21.0 banks-2.1.2 colorama-0.4.6 filelock-3.18.0 filetype-1.2.0 griffe-1.7.3 hf-xet-1.1.4 huggingface-hub-0.33.0 llama-index-core-0.12.43 llama-index-instrumentation-0.1.0 llama-index-llms-openai-0.4.7 llama-index-llms-openai-like-0.4.0 llama-index-workflows-0.2.1 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.52.4\r\n",
      "Collecting llama-index-embeddings-huggingface\r\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl.metadata (458 bytes)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.33.0)\r\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in ./.venv/lib/python3.12/site-packages (from llama-index-embeddings-huggingface) (0.12.43)\r\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\r\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.12.13)\r\n",
      "Requirement already satisfied: aiosqlite in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.21.0)\r\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.1.2)\r\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.18)\r\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\r\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.5.1)\r\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.28.1)\r\n",
      "Requirement already satisfied: llama-index-workflows>=0.2.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.2.1)\r\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.5)\r\n",
      "Requirement already satisfied: nltk>3.8.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\r\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (11.2.1)\r\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.11.7)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.32.4)\r\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (80.9.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.0.41)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.5.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.14.0)\r\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\r\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.17.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (6.5.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.20.1)\r\n",
      "Requirement already satisfied: griffe in ./.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.7.3)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.1.6)\r\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.12/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.3.8)\r\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.10)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.18.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.1.4)\r\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./.venv/lib/python3.12/site-packages (from llama-index-workflows>=0.2.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.1.0)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (8.2.1)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.5.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (2025.6.15)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.52.4)\r\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\r\n",
      "  Downloading torch-2.7.1-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\r\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\r\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\r\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\r\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.3)\r\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.2.3)\r\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\r\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\r\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.1.0)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.26.1)\r\n",
      "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.4.6)\r\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (4.9.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (0.16.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-embeddings-huggingface) (3.0.2)\r\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\r\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Downloading llama_index_embeddings_huggingface-0.5.4-py3-none-any.whl (8.9 kB)\r\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\r\n",
      "Downloading torch-2.7.1-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m68.6/68.6 MB\u001B[0m \u001B[31m7.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-macosx_12_0_arm64.whl (10.7 MB)\r\n",
      "Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl (22.4 MB)\r\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, torch, scikit-learn, sentence-transformers, llama-index-embeddings-huggingface\r\n",
      "\u001B[2K   \u001B[90m\u001B[0m \u001B[32m8/8\u001B[0m [llama-index-embeddings-huggingface]sformers]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed llama-index-embeddings-huggingface-0.5.4 mpmath-1.3.0 scikit-learn-1.7.0 scipy-1.15.3 sentence-transformers-4.1.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.1\r\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.12/site-packages (4.1.0)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.52.4)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\r\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.0)\r\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (1.15.3)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (0.33.0)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from sentence-transformers) (4.14.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.4)\r\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d3dd014f-d175-4723-ae20-9292dc9cb633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:20:31.423244Z",
     "start_time": "2025-06-19T04:20:26.497180Z"
    }
   },
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def setup_local_models(llm_model=None, embedding_model=None):\n",
    "    \"\"\"\n",
    "    Setup local LLM and embedding models with user choice\n",
    "\n",
    "    Args:\n",
    "        llm_model (str): Choose from available models in LM Studio\n",
    "        embedding_model (str): Choose embedding model type\n",
    "    \"\"\"\n",
    "\n",
    "    # Available LLM models (make sure these match what you have in LM Studio)\n",
    "    available_llm_models = {\n",
    "        \"1\": \"deepseek-coder-33b-instruct\",\n",
    "        \"2\": \"open_gpt4_8x7b_v0.2\",\n",
    "        \"3\": \"llama-3-groq-8b-tool-use\"\n",
    "    }\n",
    "\n",
    "    # Available embedding models\n",
    "    available_embedding_models = {\n",
    "        \"1\": \"all-MiniLM-L6-v2\",\n",
    "        \"2\": \"text-embedding-ada-002\"\n",
    "    }\n",
    "\n",
    "    # Local server configuration\n",
    "    local_llm_url = \"http://127.0.0.1:1234/v1\"\n",
    "\n",
    "    # Choose LLM model\n",
    "    if llm_model is None:\n",
    "        print(\"Available LLM models:\")\n",
    "        for key, model in available_llm_models.items():\n",
    "            print(f\"{key}. {model}\")\n",
    "\n",
    "        choice = input(\"Choose LLM model (1-3): \").strip()\n",
    "        llm_model = available_llm_models.get(choice, \"deepseek-coder-33b-instruct\")\n",
    "\n",
    "    print(f\"Selected LLM: {llm_model}\")\n",
    "\n",
    "    # Setup the LLM\n",
    "    Settings.llm = OpenAILike(\n",
    "        model=llm_model,\n",
    "        api_base=local_llm_url,\n",
    "        api_key=\"lm-studio\",\n",
    "        is_local=True,\n",
    "        temperature=0.1,\n",
    "        max_tokens=2048,\n",
    "    )\n",
    "\n",
    "    # Choose embedding model\n",
    "    if embedding_model is None:\n",
    "        print(\"\\nAvailable embedding models:\")\n",
    "        for key, model in available_embedding_models.items():\n",
    "            print(f\"{key}. {model}\")\n",
    "\n",
    "        choice = input(\"Choose embedding model (1-2): \").strip()\n",
    "        embedding_model = available_embedding_models.get(choice, \"1\")\n",
    "\n",
    "    # Setup embedding model based on choice\n",
    "    if embedding_model == \"2\" or embedding_model == \"text-embedding-ada-002\":\n",
    "        print(\"Selected embedding: text-embedding-ada-002 (via local server)\")\n",
    "        # Try to use OpenAI-compatible embeddings through local server\n",
    "        Settings.embed_model = OpenAIEmbedding(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            api_base=local_llm_url,\n",
    "            api_key=\"lm-studio\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"Selected embedding: all-MiniLM-L6-v2 (HuggingFace)\")\n",
    "        # Use HuggingFace embeddings\n",
    "        Settings.embed_model = HuggingFaceEmbedding(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n Setup complete!\")\n",
    "    print(f\"LLM: {Settings.llm.model}\")\n",
    "    print(f\"Embedding: {type(Settings.embed_model).__name__}\")\n",
    "\n",
    "    return Settings.llm, Settings.embed_model\n",
    "\n",
    "# Quick setup functions for faster configuration\n",
    "def setup_fast_config():\n",
    "    \"\"\"Quick setup with faster models\"\"\"\n",
    "    print(\"Setting up fast configuration...\")\n",
    "    return setup_local_models(\n",
    "        llm_model=\"llama-3-groq-8b-tool-use\",  # Usually faster than deepseek\n",
    "        embedding_model=\"1\"  # HuggingFace MiniLM\n",
    "    )\n",
    "\n",
    "def setup_quality_config():\n",
    "    \"\"\"Setup with higher quality models\"\"\"\n",
    "    print(\"Setting up quality configuration...\")\n",
    "    return setup_local_models(\n",
    "        llm_model=\"deepseek-coder-33b-instruct\",  # Higher quality but slower\n",
    "        embedding_model=\"2\"  # Ada-002 if available locally\n",
    "    )\n",
    "\n",
    "def setup_balanced_config():\n",
    "    \"\"\"Setup with balanced speed/quality\"\"\"\n",
    "    print(\"Setting up balanced configuration...\")\n",
    "    return setup_local_models(\n",
    "        llm_model=\"open_gpt4_8x7b_v0.2\",  # Balance of speed and quality\n",
    "        embedding_model=\"1\"  # Fast embeddings\n",
    "    )\n",
    "\n",
    "# Interactive setup\n",
    "print(\"=== Local Model Configuration ===\")\n",
    "print(\"Choose setup mode:\")\n",
    "print(\"1. Interactive (choose each model)\")\n",
    "print(\"2. Fast (optimized for speed)\")\n",
    "print(\"3. Quality (optimized for quality)\")\n",
    "print(\"4. Balanced (speed + quality)\")\n",
    "\n",
    "mode = input(\"Enter your choice (1-4): \").strip()\n",
    "\n",
    "if mode == \"2\":\n",
    "    setup_fast_config()\n",
    "elif mode == \"3\":\n",
    "    setup_quality_config()\n",
    "elif mode == \"4\":\n",
    "    setup_balanced_config()\n",
    "else:\n",
    "    setup_local_models()  # Interactive mode"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Local Model Configuration ===\n",
      "Choose setup mode:\n",
      "1. Interactive (choose each model)\n",
      "2. Fast (optimized for speed)\n",
      "3. Quality (optimized for quality)\n",
      "4. Balanced (speed + quality)\n",
      "Setting up balanced configuration...\n",
      "Selected LLM: open_gpt4_8x7b_v0.2\n",
      "Selected embedding: all-MiniLM-L6-v2 (HuggingFace)\n",
      "\n",
      " Setup complete!\n",
      "LLM: open_gpt4_8x7b_v0.2\n",
      "Embedding: HuggingFaceEmbedding\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setting up Vector Indexing",
   "id": "ab47686f46a292b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:20:38.420106Z",
     "start_time": "2025-06-19T04:20:38.405212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def inspect_vector_indexes(aeroflow_index=None, ecosprint_index=None,\n",
    "                           aeroflow_nodes=None, ecosprint_nodes=None):\n",
    "    \"\"\"\n",
    "    Comprehensive inspection of vector indexes and their contents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\" VECTOR INDEX INSPECTION REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print()\n",
    "\n",
    "    # 1. Check where indexes are stored\n",
    "    print(\" INDEX STORAGE LOCATIONS\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # LlamaIndex typically stores indexes in memory by default\n",
    "    # But let's check for any persistent storage\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "    # Check for common LlamaIndex storage directories\n",
    "    storage_dirs = ['./storage', './index_storage', './vector_store']\n",
    "    for storage_dir in storage_dirs:\n",
    "        if os.path.exists(storage_dir):\n",
    "            print(f\"Found storage directory: {storage_dir}\")\n",
    "            for item in os.listdir(storage_dir):\n",
    "                print(f\"  - {item}\")\n",
    "        else:\n",
    "            print(f\"No storage found at: {storage_dir}\")\n",
    "\n",
    "    print(\"\\n Note: By default, VectorStoreIndex stores data in memory.\")\n",
    "    print(\"   To persist indexes, you'd need to use index.storage_context.persist()\")\n",
    "\n",
    "    # 2. Inspect AeroFlow Index\n",
    "    if aeroflow_index and aeroflow_nodes:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\" AEROFLOW INDEX ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        inspect_single_index(\"AeroFlow\", aeroflow_index, aeroflow_nodes)\n",
    "\n",
    "    # 3. Inspect EcoSprint Index\n",
    "    if ecosprint_index and ecosprint_nodes:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\" ECOSPRINT INDEX ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        inspect_single_index(\"EcoSprint\", ecosprint_index, ecosprint_nodes)\n",
    "\n",
    "def inspect_single_index(name, index, nodes):\n",
    "    \"\"\"\n",
    "    Detailed inspection of a single vector index\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n {name} INDEX OVERVIEW\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Basic stats\n",
    "    print(f\"Total nodes: {len(nodes)}\")\n",
    "\n",
    "    # Vector store info\n",
    "    vector_store = index.vector_store\n",
    "    print(f\"Vector store type: {type(vector_store).__name__}\")\n",
    "\n",
    "    # Try to get vector store stats\n",
    "    try:\n",
    "        if hasattr(vector_store, 'client'):\n",
    "            print(f\"Vector store client: {type(vector_store.client).__name__}\")\n",
    "        if hasattr(vector_store, '_data'):\n",
    "            if hasattr(vector_store._data, 'embedding_dict'):\n",
    "                print(f\"Stored vectors: {len(vector_store._data.embedding_dict)}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Node analysis\n",
    "    print(f\"\\n {name} NODE CONTENT ANALYSIS\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    if nodes:\n",
    "        # Text length statistics\n",
    "        text_lengths = [len(node.text) for node in nodes]\n",
    "        print(f\"Average chunk size: {np.mean(text_lengths):.0f} characters\")\n",
    "        print(f\"Min chunk size: {min(text_lengths)} characters\")\n",
    "        print(f\"Max chunk size: {max(text_lengths)} characters\")\n",
    "\n",
    "        # Show first few chunks\n",
    "        print(f\"\\n SAMPLE CHUNKS FROM {name}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for i, node in enumerate(nodes[:3]):  # Show first 3 chunks\n",
    "            print(f\"\\n--- Chunk {i+1} ---\")\n",
    "            print(f\"Node ID: {node.node_id}\")\n",
    "            print(f\"Length: {len(node.text)} characters\")\n",
    "\n",
    "            # Show metadata if available\n",
    "            if hasattr(node, 'metadata') and node.metadata:\n",
    "                print(f\"Metadata: {node.metadata}\")\n",
    "\n",
    "            # Show first 200 chars of content\n",
    "            preview = node.text[:200] + \"...\" if len(node.text) > 200 else node.text\n",
    "            print(f\"Content preview:\\n{preview}\")\n",
    "\n",
    "            # Check if node has embedding\n",
    "            if hasattr(node, 'embedding') and node.embedding:\n",
    "                print(f\"Embedding dimension: {len(node.embedding)}\")\n",
    "            else:\n",
    "                print(\"Embedding: Not stored in node\")\n",
    "\n",
    "def save_index_contents_to_files(aeroflow_nodes=None, ecosprint_nodes=None):\n",
    "    \"\"\"\n",
    "    Save detailed index contents to files for inspection\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n SAVING INDEX CONTENTS TO FILES\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if aeroflow_nodes:\n",
    "        filename = f\"aeroflow_chunks_{timestamp}.txt\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"AEROFLOW DOCUMENT CHUNKS\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "            for i, node in enumerate(aeroflow_nodes):\n",
    "                f.write(f\"CHUNK {i+1}\\n\")\n",
    "                f.write(\"-\" * 20 + \"\\n\")\n",
    "                f.write(f\"Node ID: {node.node_id}\\n\")\n",
    "                f.write(f\"Length: {len(node.text)} characters\\n\")\n",
    "                if hasattr(node, 'metadata') and node.metadata:\n",
    "                    f.write(f\"Metadata: {node.metadata}\\n\")\n",
    "                f.write(f\"Content:\\n{node.text}\\n\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        print(f\" AeroFlow chunks saved to: {filename}\")\n",
    "\n",
    "    if ecosprint_nodes:\n",
    "        filename = f\"ecosprint_chunks_{timestamp}.txt\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"ECOSPRINT DOCUMENT CHUNKS\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "            for i, node in enumerate(ecosprint_nodes):\n",
    "                f.write(f\"CHUNK {i+1}\\n\")\n",
    "                f.write(\"-\" * 20 + \"\\n\")\n",
    "                f.write(f\"Node ID: {node.node_id}\\n\")\n",
    "                f.write(f\"Length: {len(node.text)} characters\\n\")\n",
    "                if hasattr(node, 'metadata') and node.metadata:\n",
    "                    f.write(f\"Metadata: {node.metadata}\\n\")\n",
    "                f.write(f\"Content:\\n{node.text}\\n\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        print(f\" EcoSprint chunks saved to: {filename}\")\n",
    "\n",
    "def analyze_embedding_vectors(index, sample_size=5):\n",
    "    \"\"\"\n",
    "    Analyze the embedding vectors in the index\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n EMBEDDING VECTOR ANALYSIS\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    try:\n",
    "        # Get a few sample embeddings\n",
    "        vector_store = index.vector_store\n",
    "\n",
    "        if hasattr(vector_store, '_data') and hasattr(vector_store._data, 'embedding_dict'):\n",
    "            embeddings_dict = vector_store._data.embedding_dict\n",
    "\n",
    "            if embeddings_dict:\n",
    "                # Get sample embeddings\n",
    "                sample_embeddings = list(embeddings_dict.values())[:sample_size]\n",
    "\n",
    "                if sample_embeddings:\n",
    "                    # Analyze dimensions\n",
    "                    embedding_dim = len(sample_embeddings[0])\n",
    "                    print(f\"Embedding dimension: {embedding_dim}\")\n",
    "\n",
    "                    # Basic statistics\n",
    "                    sample_array = np.array(sample_embeddings)\n",
    "                    print(f\"Sample size: {len(sample_embeddings)}\")\n",
    "                    print(f\"Mean value: {np.mean(sample_array):.6f}\")\n",
    "                    print(f\"Std deviation: {np.std(sample_array):.6f}\")\n",
    "                    print(f\"Min value: {np.min(sample_array):.6f}\")\n",
    "                    print(f\"Max value: {np.max(sample_array):.6f}\")\n",
    "                else:\n",
    "                    print(\"No embedding vectors found\")\n",
    "            else:\n",
    "                print(\"Embedding dictionary is empty\")\n",
    "        else:\n",
    "            print(\"Cannot access embedding vectors (may be stored differently)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing embeddings: {e}\")\n",
    "\n",
    "# Usage function\n",
    "def run_full_inspection():\n",
    "    \"\"\"\n",
    "    Run this after creating your indexes to get a complete inspection\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the variables are available in your scope\n",
    "    try:\n",
    "        # These should be defined in your main code\n",
    "        inspect_vector_indexes(\n",
    "            aeroflow_index=aeroflow_index if 'aeroflow_index' in globals() else None,\n",
    "            ecosprint_index=ecosprint_index if 'ecosprint_index' in globals() else None,\n",
    "            aeroflow_nodes=aeroflow_nodes if 'aeroflow_nodes' in globals() else None,\n",
    "            ecosprint_nodes=ecosprint_nodes if 'ecosprint_nodes' in globals() else None\n",
    "        )\n",
    "\n",
    "        # Save contents to files\n",
    "        save_index_contents_to_files(\n",
    "            aeroflow_nodes=aeroflow_nodes if 'aeroflow_nodes' in globals() else None,\n",
    "            ecosprint_nodes=ecosprint_nodes if 'ecosprint_nodes' in globals() else None\n",
    "        )\n",
    "\n",
    "        # Analyze embeddings\n",
    "        if 'aeroflow_index' in globals():\n",
    "            print(\"\\n AEROFLOW EMBEDDINGS\")\n",
    "            analyze_embedding_vectors(aeroflow_index)\n",
    "\n",
    "        if 'ecosprint_index' in globals():\n",
    "            print(\"\\n ECOSPRINT EMBEDDINGS\")\n",
    "            analyze_embedding_vectors(ecosprint_index)\n",
    "\n",
    "    except NameError as e:\n",
    "        print(f\" Error: {e}\")\n",
    "        print(\"Make sure to run this after creating your indexes!\")\n",
    "\n",
    "print(\" Vector Index Inspector loaded!\")\n",
    "print(\"After creating your indexes, run: run_full_inspection()\")"
   ],
   "id": "4bc7137a95711948",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vector Index Inspector loaded!\n",
      "After creating your indexes, run: run_full_inspection()\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:21:30.837274Z",
     "start_time": "2025-06-19T04:21:30.716516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create indexes for vector search\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex\n",
    "import os\n",
    "\n",
    "# Initialize the splitter\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "# Setup Aeroflow document index\n",
    "#-------------------------------------------------------------------\n",
    "print(\"Loading AeroFlow documents...\")\n",
    "\n",
    "# Check if file exists\n",
    "aeroflow_file = \"AeroFlow_Specification_Document.pdf\"\n",
    "if not os.path.exists(aeroflow_file):\n",
    "    print(f\"Warning: {aeroflow_file} not found!\")\n",
    "    aeroflow_index = None\n",
    "    aeroflow_nodes = None\n",
    "    aeroflow_query_engine = None\n",
    "else:\n",
    "    aeroflow_documents = SimpleDirectoryReader(\n",
    "        input_files=[aeroflow_file]\n",
    "    ).load_data()\n",
    "\n",
    "    print(f\"Loaded {len(aeroflow_documents)} AeroFlow documents\")\n",
    "\n",
    "    # Read documents into nodes\n",
    "    aeroflow_nodes = splitter.get_nodes_from_documents(aeroflow_documents)\n",
    "    print(f\"Created {len(aeroflow_nodes)} AeroFlow nodes\")\n",
    "\n",
    "    # Create a vector store\n",
    "    print(\"Creating AeroFlow vector index...\")\n",
    "    aeroflow_index = VectorStoreIndex(aeroflow_nodes)\n",
    "\n",
    "    # Create a query engine\n",
    "    aeroflow_query_engine = aeroflow_index.as_query_engine()\n",
    "    print(\"AeroFlow query engine ready!\")\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "# Setup EchoSprint document index\n",
    "#-------------------------------------------------------------------\n",
    "print(\"\\nLoading EcoSprint documents...\")\n",
    "\n",
    "# Check if file exists\n",
    "ecosprint_file = \"EcoSprint_Specification_Document.pdf\"\n",
    "if not os.path.exists(ecosprint_file):\n",
    "    print(f\"Warning: {ecosprint_file} not found!\")\n",
    "    ecosprint_index = None\n",
    "    ecosprint_nodes = None\n",
    "    ecosprint_query_engine = None\n",
    "else:\n",
    "    ecosprint_documents = SimpleDirectoryReader(\n",
    "        input_files=[ecosprint_file]\n",
    "    ).load_data()\n",
    "\n",
    "    print(f\"Loaded {len(ecosprint_documents)} EcoSprint documents\")\n",
    "\n",
    "    # Read documents into nodes\n",
    "    ecosprint_nodes = splitter.get_nodes_from_documents(ecosprint_documents)\n",
    "    print(f\"Created {len(ecosprint_nodes)} EcoSprint nodes\")\n",
    "\n",
    "    # Create a vector store\n",
    "    print(\"Creating EcoSprint vector index...\")\n",
    "    ecosprint_index = VectorStoreIndex(ecosprint_nodes)\n",
    "\n",
    "    # Create a query engine\n",
    "    ecosprint_query_engine = ecosprint_index.as_query_engine()\n",
    "    print(\"EcoSprint query engine ready!\")\n",
    "\n",
    "print(\"\\nVector indexing complete!\")\n",
    "print(\"Both query engines are ready to use with your local LLM setup.\")\n",
    "\n",
    "# ADD THIS SECTION FOR INSPECTION\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" RUNNING INDEX INSPECTION...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Run the inspection\n",
    "inspect_vector_indexes(\n",
    "    aeroflow_index=aeroflow_index,\n",
    "    ecosprint_index=ecosprint_index,\n",
    "    aeroflow_nodes=aeroflow_nodes,\n",
    "    ecosprint_nodes=ecosprint_nodes\n",
    ")\n",
    "\n",
    "# Save detailed contents to files\n",
    "save_index_contents_to_files(\n",
    "    aeroflow_nodes=aeroflow_nodes,\n",
    "    ecosprint_nodes=ecosprint_nodes\n",
    ")\n",
    "\n",
    "# Analyze embeddings\n",
    "if aeroflow_index:\n",
    "    print(\"\\n AEROFLOW EMBEDDINGS\")\n",
    "    analyze_embedding_vectors(aeroflow_index)\n",
    "\n",
    "if ecosprint_index:\n",
    "    print(\"\\n ECOSPRINT EMBEDDINGS\")\n",
    "    analyze_embedding_vectors(ecosprint_index)"
   ],
   "id": "07ad3b12-10f1-4447-b63c-10f903730878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AeroFlow documents...\n",
      "Loaded 2 AeroFlow documents\n",
      "Created 2 AeroFlow nodes\n",
      "Creating AeroFlow vector index...\n",
      "AeroFlow query engine ready!\n",
      "\n",
      "Loading EcoSprint documents...\n",
      "Loaded 2 EcoSprint documents\n",
      "Created 2 EcoSprint nodes\n",
      "Creating EcoSprint vector index...\n",
      "EcoSprint query engine ready!\n",
      "\n",
      "Vector indexing complete!\n",
      "Both query engines are ready to use with your local LLM setup.\n",
      "\n",
      "============================================================\n",
      " RUNNING INDEX INSPECTION...\n",
      "============================================================\n",
      "================================================================================\n",
      " VECTOR INDEX INSPECTION REPORT\n",
      "================================================================================\n",
      "Generated at: 2025-06-18 23:21:30\n",
      "\n",
      " INDEX STORAGE LOCATIONS\n",
      "----------------------------------------\n",
      "Current working directory: /Users/jarotball/Setups/agentic-ai-for-developers-concepts-and-applications-for-enterprises-3913172\n",
      "No storage found at: ./storage\n",
      "No storage found at: ./index_storage\n",
      "No storage found at: ./vector_store\n",
      "\n",
      " Note: By default, VectorStoreIndex stores data in memory.\n",
      "   To persist indexes, you'd need to use index.storage_context.persist()\n",
      "\n",
      "============================================================\n",
      " AEROFLOW INDEX ANALYSIS\n",
      "============================================================\n",
      "\n",
      " AeroFlow INDEX OVERVIEW\n",
      "------------------------------\n",
      "Total nodes: 2\n",
      "Vector store type: SimpleVectorStore\n",
      "Vector store client: NoneType\n",
      "Stored vectors: 2\n",
      "\n",
      " AeroFlow NODE CONTENT ANALYSIS\n",
      "-----------------------------------\n",
      "Average chunk size: 1239 characters\n",
      "Min chunk size: 262 characters\n",
      "Max chunk size: 2216 characters\n",
      "\n",
      " SAMPLE CHUNKS FROM AeroFlow\n",
      "------------------------------\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Node ID: 96adfe61-c901-4161-aa79-9372d5c4a8bf\n",
      "Length: 2216 characters\n",
      "Metadata: {'page_label': '1', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "AeroFlow\n",
      "Detailed\n",
      "Specification\n",
      "Document\n",
      "1.\n",
      "Overview\n",
      "\n",
      "AeroFlow\n",
      "is\n",
      "the\n",
      "ideal\n",
      "family\n",
      "electric\n",
      "vehicle,\n",
      "balancing\n",
      "space,\n",
      "comfort,\n",
      "and\n",
      "efficiency.\n",
      "Designed\n",
      "with\n",
      "family\n",
      "needs\n",
      "in\n",
      "mind,\n",
      "it\n",
      "offers\n",
      "a\n",
      "safe,\n",
      "sp...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Node ID: 56d960a9-b185-4182-8f1d-d3e4b2e9a1b3\n",
      "Length: 262 characters\n",
      "Metadata: {'page_label': '2', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "7.\n",
      "Pricing\n",
      "and\n",
      "Models\n",
      "\n",
      "Pricing\n",
      "Structure:\n",
      "Starts\n",
      "at\n",
      "an\n",
      "accessible\n",
      "price\n",
      "point\n",
      "of\n",
      "$40,000,\n",
      "offering\n",
      "excellent\n",
      "value\n",
      "for\n",
      "a\n",
      "family\n",
      "vehicle.\n",
      "\n",
      "Model\n",
      "Variants:\n",
      "Available\n",
      "in\n",
      "Basic,\n",
      "Comfort,\n",
      "and\n",
      "Luxury\n",
      "edit...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "============================================================\n",
      " ECOSPRINT INDEX ANALYSIS\n",
      "============================================================\n",
      "\n",
      " EcoSprint INDEX OVERVIEW\n",
      "------------------------------\n",
      "Total nodes: 2\n",
      "Vector store type: SimpleVectorStore\n",
      "Vector store client: NoneType\n",
      "Stored vectors: 2\n",
      "\n",
      " EcoSprint NODE CONTENT ANALYSIS\n",
      "-----------------------------------\n",
      "Average chunk size: 1396 characters\n",
      "Min chunk size: 624 characters\n",
      "Max chunk size: 2167 characters\n",
      "\n",
      " SAMPLE CHUNKS FROM EcoSprint\n",
      "------------------------------\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Node ID: ad522aa3-3b57-4312-b273-6e4f129004df\n",
      "Length: 2167 characters\n",
      "Metadata: {'page_label': '1', 'file_name': 'EcoSprint_Specification_Document.pdf', 'file_path': 'EcoSprint_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 38110, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "EcoSprint\n",
      "Specification\n",
      "Document\n",
      "1.\n",
      "Overview\n",
      "\n",
      "The\n",
      "EcoSprint\n",
      "is\n",
      "a\n",
      "revolutionary\n",
      "electric\n",
      "vehicle\n",
      "(EV)\n",
      "designed\n",
      "for\n",
      "efficiency\n",
      "and\n",
      "performance.\n",
      "With\n",
      "its\n",
      "sleek\n",
      "design\n",
      "and\n",
      "state-of-the-art\n",
      "technology,\n",
      "th...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Node ID: 120aff83-7734-466b-ac3f-6b2e7701dd84\n",
      "Length: 624 characters\n",
      "Metadata: {'page_label': '2', 'file_name': 'EcoSprint_Specification_Document.pdf', 'file_path': 'EcoSprint_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 38110, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "6.\n",
      "Maintenance\n",
      "and\n",
      "Warranty\n",
      "\n",
      "Regular\n",
      "Maintenance:\n",
      "Low\n",
      "maintenance\n",
      "requirements\n",
      "with\n",
      "recommended\n",
      "checks\n",
      "every\n",
      "10,000\n",
      "miles.\n",
      "Easy\n",
      "scheduling\n",
      "of\n",
      "service\n",
      "appointments\n",
      "through\n",
      "the\n",
      "mobile\n",
      "app.\n",
      "\n",
      "Warranty:\n",
      "...\n",
      "Embedding: Not stored in node\n",
      "\n",
      " SAVING INDEX CONTENTS TO FILES\n",
      "----------------------------------------\n",
      " AeroFlow chunks saved to: aeroflow_chunks_20250618_232130.txt\n",
      " EcoSprint chunks saved to: ecosprint_chunks_20250618_232130.txt\n",
      "\n",
      " AEROFLOW EMBEDDINGS\n",
      "\n",
      " EMBEDDING VECTOR ANALYSIS\n",
      "-----------------------------------\n",
      "Embedding dimension: 384\n",
      "Sample size: 2\n",
      "Mean value: -0.001544\n",
      "Std deviation: 0.051008\n",
      "Min value: -0.137559\n",
      "Max value: 0.155384\n",
      "\n",
      " ECOSPRINT EMBEDDINGS\n",
      "\n",
      " EMBEDDING VECTOR ANALYSIS\n",
      "-----------------------------------\n",
      "Embedding dimension: 384\n",
      "Sample size: 2\n",
      "Mean value: -0.000305\n",
      "Std deviation: 0.051030\n",
      "Min value: -0.180898\n",
      "Max value: 0.171049\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:21:49.000971Z",
     "start_time": "2025-06-19T04:21:48.996247Z"
    }
   },
   "cell_type": "code",
   "source": "run_full_inspection()",
   "id": "b847fc1f8cc30c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " VECTOR INDEX INSPECTION REPORT\n",
      "================================================================================\n",
      "Generated at: 2025-06-18 23:21:48\n",
      "\n",
      " INDEX STORAGE LOCATIONS\n",
      "----------------------------------------\n",
      "Current working directory: /Users/jarotball/Setups/agentic-ai-for-developers-concepts-and-applications-for-enterprises-3913172\n",
      "No storage found at: ./storage\n",
      "No storage found at: ./index_storage\n",
      "No storage found at: ./vector_store\n",
      "\n",
      " Note: By default, VectorStoreIndex stores data in memory.\n",
      "   To persist indexes, you'd need to use index.storage_context.persist()\n",
      "\n",
      "============================================================\n",
      " AEROFLOW INDEX ANALYSIS\n",
      "============================================================\n",
      "\n",
      " AeroFlow INDEX OVERVIEW\n",
      "------------------------------\n",
      "Total nodes: 2\n",
      "Vector store type: SimpleVectorStore\n",
      "Vector store client: NoneType\n",
      "Stored vectors: 2\n",
      "\n",
      " AeroFlow NODE CONTENT ANALYSIS\n",
      "-----------------------------------\n",
      "Average chunk size: 1239 characters\n",
      "Min chunk size: 262 characters\n",
      "Max chunk size: 2216 characters\n",
      "\n",
      " SAMPLE CHUNKS FROM AeroFlow\n",
      "------------------------------\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Node ID: 96adfe61-c901-4161-aa79-9372d5c4a8bf\n",
      "Length: 2216 characters\n",
      "Metadata: {'page_label': '1', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "AeroFlow\n",
      "Detailed\n",
      "Specification\n",
      "Document\n",
      "1.\n",
      "Overview\n",
      "\n",
      "AeroFlow\n",
      "is\n",
      "the\n",
      "ideal\n",
      "family\n",
      "electric\n",
      "vehicle,\n",
      "balancing\n",
      "space,\n",
      "comfort,\n",
      "and\n",
      "efficiency.\n",
      "Designed\n",
      "with\n",
      "family\n",
      "needs\n",
      "in\n",
      "mind,\n",
      "it\n",
      "offers\n",
      "a\n",
      "safe,\n",
      "sp...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Node ID: 56d960a9-b185-4182-8f1d-d3e4b2e9a1b3\n",
      "Length: 262 characters\n",
      "Metadata: {'page_label': '2', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "7.\n",
      "Pricing\n",
      "and\n",
      "Models\n",
      "\n",
      "Pricing\n",
      "Structure:\n",
      "Starts\n",
      "at\n",
      "an\n",
      "accessible\n",
      "price\n",
      "point\n",
      "of\n",
      "$40,000,\n",
      "offering\n",
      "excellent\n",
      "value\n",
      "for\n",
      "a\n",
      "family\n",
      "vehicle.\n",
      "\n",
      "Model\n",
      "Variants:\n",
      "Available\n",
      "in\n",
      "Basic,\n",
      "Comfort,\n",
      "and\n",
      "Luxury\n",
      "edit...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "============================================================\n",
      " ECOSPRINT INDEX ANALYSIS\n",
      "============================================================\n",
      "\n",
      " EcoSprint INDEX OVERVIEW\n",
      "------------------------------\n",
      "Total nodes: 2\n",
      "Vector store type: SimpleVectorStore\n",
      "Vector store client: NoneType\n",
      "Stored vectors: 2\n",
      "\n",
      " EcoSprint NODE CONTENT ANALYSIS\n",
      "-----------------------------------\n",
      "Average chunk size: 1396 characters\n",
      "Min chunk size: 624 characters\n",
      "Max chunk size: 2167 characters\n",
      "\n",
      " SAMPLE CHUNKS FROM EcoSprint\n",
      "------------------------------\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Node ID: ad522aa3-3b57-4312-b273-6e4f129004df\n",
      "Length: 2167 characters\n",
      "Metadata: {'page_label': '1', 'file_name': 'EcoSprint_Specification_Document.pdf', 'file_path': 'EcoSprint_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 38110, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "EcoSprint\n",
      "Specification\n",
      "Document\n",
      "1.\n",
      "Overview\n",
      "\n",
      "The\n",
      "EcoSprint\n",
      "is\n",
      "a\n",
      "revolutionary\n",
      "electric\n",
      "vehicle\n",
      "(EV)\n",
      "designed\n",
      "for\n",
      "efficiency\n",
      "and\n",
      "performance.\n",
      "With\n",
      "its\n",
      "sleek\n",
      "design\n",
      "and\n",
      "state-of-the-art\n",
      "technology,\n",
      "th...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Node ID: 120aff83-7734-466b-ac3f-6b2e7701dd84\n",
      "Length: 624 characters\n",
      "Metadata: {'page_label': '2', 'file_name': 'EcoSprint_Specification_Document.pdf', 'file_path': 'EcoSprint_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 38110, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "6.\n",
      "Maintenance\n",
      "and\n",
      "Warranty\n",
      "\n",
      "Regular\n",
      "Maintenance:\n",
      "Low\n",
      "maintenance\n",
      "requirements\n",
      "with\n",
      "recommended\n",
      "checks\n",
      "every\n",
      "10,000\n",
      "miles.\n",
      "Easy\n",
      "scheduling\n",
      "of\n",
      "service\n",
      "appointments\n",
      "through\n",
      "the\n",
      "mobile\n",
      "app.\n",
      "\n",
      "Warranty:\n",
      "...\n",
      "Embedding: Not stored in node\n",
      "\n",
      " SAVING INDEX CONTENTS TO FILES\n",
      "----------------------------------------\n",
      " AeroFlow chunks saved to: aeroflow_chunks_20250618_232148.txt\n",
      " EcoSprint chunks saved to: ecosprint_chunks_20250618_232148.txt\n",
      "\n",
      " AEROFLOW EMBEDDINGS\n",
      "\n",
      " EMBEDDING VECTOR ANALYSIS\n",
      "-----------------------------------\n",
      "Embedding dimension: 384\n",
      "Sample size: 2\n",
      "Mean value: -0.001544\n",
      "Std deviation: 0.051008\n",
      "Min value: -0.137559\n",
      "Max value: 0.155384\n",
      "\n",
      " ECOSPRINT EMBEDDINGS\n",
      "\n",
      " EMBEDDING VECTOR ANALYSIS\n",
      "-----------------------------------\n",
      "Embedding dimension: 384\n",
      "Sample size: 2\n",
      "Mean value: -0.000305\n",
      "Std deviation: 0.051030\n",
      "Min value: -0.180898\n",
      "Max value: 0.171049\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 03.04. Setup the Agentic Router",
   "id": "f75954cc-cf76-4a92-ac92-580b4393b885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:59:40.315973Z",
     "start_time": "2025-06-19T04:59:40.237009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Fixes for Router JSON Errors\n",
    "# from llama_index.core.tools import QueryEngineTool\n",
    "# from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "# from llama_index.core.selectors import LLMSingleSelector, PydanticSingleSelector\n",
    "# from llama_index.core import Settings\n",
    "#\n",
    "# print(\"Setting up Agentic Router...\")\n",
    "#\n",
    "# # Create a query engine Tool for AeroFlow\n",
    "# aeroflow_tool = QueryEngineTool.from_defaults(\n",
    "#     query_engine=aeroflow_query_engine,\n",
    "#     name=\"AeroFlow_specifications\",\n",
    "#     description=(\n",
    "#         \"Use this tool for questions about AeroFlow vehicle specifications, including: \"\n",
    "#         \"design details, features, technology components, maintenance procedures, \"\n",
    "#         \"warranty information, performance metrics, and technical specifications. \"\n",
    "#         \"This covers all AeroFlow-related documentation.\"\n",
    "#     ),\n",
    "# )\n",
    "#\n",
    "# # Create a query engine Tool for EcoSprint\n",
    "# ecosprint_tool = QueryEngineTool.from_defaults(\n",
    "#     query_engine=ecosprint_query_engine,\n",
    "#     name=\"EcoSprint_specifications\",\n",
    "#     description=(\n",
    "#         \"Use this tool for questions about EcoSprint vehicle specifications, including: \"\n",
    "#         \"design details, features, technology components, maintenance procedures, \"\n",
    "#         \"warranty information, performance metrics, and technical specifications. \"\n",
    "#         \"This covers all EcoSprint-related documentation.\"\n",
    "#     ),\n",
    "# )\n",
    "#\n",
    "# # Create a Router Agent with improved selector configuration\n",
    "# print(\"Creating router with local LLM selector...\")\n",
    "# router_agent = RouterQueryEngine(\n",
    "#     selector=LLMSingleSelector.from_defaults(\n",
    "#         llm=Settings.llm  # Explicitly use our local LLM\n",
    "#     ),\n",
    "#     query_engine_tools=[\n",
    "#         aeroflow_tool,\n",
    "#         ecosprint_tool,\n",
    "#     ],\n",
    "#     verbose=True  # Shows which tool is selected for each query\n",
    "# )\n",
    "#\n",
    "# print(\"Agentic Router setup complete!\")\n",
    "# print(f\"Available tools: {[tool.metadata.name for tool in [aeroflow_tool, ecosprint_tool]]}\")\n",
    "#\n"
   ],
   "id": "767a0751-5238-4df8-816f-8436a34f96bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Agentic Router...\n",
      "Creating router with local LLM selector...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model name open_gpt4_8x7b_v0.2 does not support function calling API. ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[51]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;66;03m# Create a Router Agent with improved selector configuration\u001B[39;00m\n\u001B[32m     34\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mCreating router with local LLM selector...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     35\u001B[39m router_agent = RouterQueryEngine(\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m     selector=\u001B[43mPydanticSingleSelector\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_defaults\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m        \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mSettings\u001B[49m\u001B[43m.\u001B[49m\u001B[43mllm\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Explicitly use our local LLM\u001B[39;49;00m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m     39\u001B[39m     query_engine_tools=[\n\u001B[32m     40\u001B[39m         aeroflow_tool,\n\u001B[32m     41\u001B[39m         ecosprint_tool,\n\u001B[32m     42\u001B[39m     ],\n\u001B[32m     43\u001B[39m     verbose=\u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# Shows which tool is selected for each query\u001B[39;00m\n\u001B[32m     44\u001B[39m )\n\u001B[32m     46\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mAgentic Router setup complete!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     47\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAvailable tools: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m[tool.metadata.name\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mtool\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m[aeroflow_tool,\u001B[38;5;250m \u001B[39mecosprint_tool]]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Setups/agentic-ai-for-developers-concepts-and-applications-for-enterprises-3913172/.venv/lib/python3.12/site-packages/llama_index/core/selectors/pydantic_selectors.py:61\u001B[39m, in \u001B[36mPydanticSingleSelector.from_defaults\u001B[39m\u001B[34m(cls, program, llm, prompt_template_str, verbose)\u001B[39m\n\u001B[32m     56\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[32m     57\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m`llama-index-program-openai` package is missing. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     58\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mPlease install using `pip install llama-index-program-openai`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     59\u001B[39m     )\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m program \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m     program = \u001B[43mOpenAIPydanticProgram\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_defaults\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     62\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mSingleSelection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     63\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompt_template_str\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt_template_str\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m        \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m=\u001B[49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(selector_program=program)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Setups/agentic-ai-for-developers-concepts-and-applications-for-enterprises-3913172/.venv/lib/python3.12/site-packages/llama_index/program/openai/base.py:129\u001B[39m, in \u001B[36mOpenAIPydanticProgram.from_defaults\u001B[39m\u001B[34m(cls, output_cls, prompt_template_str, prompt, llm, verbose, allow_multiple, tool_choice, **kwargs)\u001B[39m\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    125\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mOpenAIPydanticProgram only supports OpenAI LLMs. \u001B[39m\u001B[33m\"\u001B[39m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mGot: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(llm)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    126\u001B[39m     )\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m llm.metadata.is_function_calling_model:\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    130\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel name \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mllm.metadata.model_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not support \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    131\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mfunction calling API. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    132\u001B[39m     )\n\u001B[32m    134\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prompt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m prompt_template_str \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    135\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mMust provide either prompt or prompt_template_str.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mValueError\u001B[39m: Model name open_gpt4_8x7b_v0.2 does not support function calling API. "
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:08:31.141617Z",
     "start_time": "2025-06-19T05:08:18.434285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Working Router Solutions for Local LLMs\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "from llama_index.core import Settings\n",
    "\n",
    "print(\"Setting up Agentic Router...\")\n",
    "\n",
    "# Create tools (same as before)\n",
    "aeroflow_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=aeroflow_query_engine,\n",
    "    name=\"AeroFlow_specifications\",\n",
    "    description=(\n",
    "        \"Use this tool for questions about AeroFlow vehicle specifications, including: \"\n",
    "        \"design details, features, technology components, maintenance procedures, \"\n",
    "        \"warranty information, performance metrics, and technical specifications. \"\n",
    "        \"This covers all AeroFlow-related documentation.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "ecosprint_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=ecosprint_query_engine,\n",
    "    name=\"EcoSprint_specifications\",\n",
    "    description=(\n",
    "        \"Use this tool for questions about EcoSprint vehicle specifications, including: \"\n",
    "        \"design details, features, technology components, maintenance procedures, \"\n",
    "        \"warranty information, performance metrics, and technical specifications. \"\n",
    "        \"This covers all EcoSprint-related documentation.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# SOLUTION 1: Better LLMSingleSelector with JSON Retry Logic\n",
    "# ============================================================================\n",
    "\n",
    "def create_robust_llm_router():\n",
    "    \"\"\"Create router with better error handling for JSON issues\"\"\"\n",
    "\n",
    "    from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "    # Create a more conservative LLM configuration for routing\n",
    "    routing_llm = OpenAILike(\n",
    "        model=Settings.llm.model,\n",
    "        api_base=Settings.llm.api_base,\n",
    "        api_key=Settings.llm.api_key,\n",
    "        is_local=True,\n",
    "        temperature=0.0,  # Most deterministic\n",
    "        max_tokens=200,   # Short responses for JSON\n",
    "        request_timeout=30.0\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        router_agent = RouterQueryEngine(\n",
    "            selector=LLMSingleSelector.from_defaults(\n",
    "                llm=routing_llm\n",
    "            ),\n",
    "            query_engine_tools=[aeroflow_tool, ecosprint_tool],\n",
    "            verbose=True\n",
    "        )\n",
    "        print(\" LLM Router created successfully!\")\n",
    "        return router_agent\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" LLM Router failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# SOLUTION 2: Simple Keyword-Based Router (Most Reliable)\n",
    "# ============================================================================\n",
    "\n",
    "class SimpleSmartRouter:\n",
    "    \"\"\"A simple but effective keyword-based router\"\"\"\n",
    "\n",
    "    def __init__(self, aeroflow_engine, ecosprint_engine):\n",
    "        self.aeroflow_engine = aeroflow_engine\n",
    "        self.ecosprint_engine = ecosprint_engine\n",
    "        self.query_count = 0\n",
    "\n",
    "    def query(self, query_str):\n",
    "        \"\"\"Smart routing based on keywords and context\"\"\"\n",
    "\n",
    "        self.query_count += 1\n",
    "        query_lower = query_str.lower()\n",
    "\n",
    "        print(f\"\\n Router Decision #{self.query_count}\")\n",
    "        print(f\"Query: '{query_str}'\")\n",
    "\n",
    "        # Analyze query for routing\n",
    "        aeroflow_score = 0\n",
    "        ecosprint_score = 0\n",
    "\n",
    "        # Check for explicit mentions\n",
    "        if \"aeroflow\" in query_lower:\n",
    "            aeroflow_score += 10\n",
    "            print(\"   + AeroFlow explicitly mentioned (+10)\")\n",
    "\n",
    "        if \"ecosprint\" in query_lower:\n",
    "            ecosprint_score += 10\n",
    "            print(\"   + EcoSprint explicitly mentioned (+10)\")\n",
    "\n",
    "        # Check for contextual keywords\n",
    "        aeroflow_keywords = [\"aero\", \"flow\", \"aerodynamic\"]\n",
    "        ecosprint_keywords = [\"eco\", \"sprint\", \"environment\", \"green\"]\n",
    "\n",
    "        for keyword in aeroflow_keywords:\n",
    "            if keyword in query_lower:\n",
    "                aeroflow_score += 2\n",
    "                print(f\"   + AeroFlow keyword '{keyword}' found (+2)\")\n",
    "\n",
    "        for keyword in ecosprint_keywords:\n",
    "            if keyword in query_lower:\n",
    "                ecosprint_score += 2\n",
    "                print(f\"   + EcoSprint keyword '{keyword}' found (+2)\")\n",
    "\n",
    "        # Make decision\n",
    "        if aeroflow_score > ecosprint_score:\n",
    "            print(f\"    Routing to AeroFlow (score: {aeroflow_score} vs {ecosprint_score})\")\n",
    "            return self.aeroflow_engine.query(query_str)\n",
    "        elif ecosprint_score > aeroflow_score:\n",
    "            print(f\"    Routing to EcoSprint (score: {ecosprint_score} vs {aeroflow_score})\")\n",
    "            return self.ecosprint_engine.query(query_str)\n",
    "        else:\n",
    "            # Tie or no specific keywords - alternate or use default logic\n",
    "            print(f\"    Ambiguous query (both scored {aeroflow_score})\")\n",
    "\n",
    "            # For comparison questions, try AeroFlow first\n",
    "            comparison_words = [\"better\", \"compare\", \"vs\", \"versus\", \"which\", \"best\"]\n",
    "            if any(word in query_lower for word in comparison_words):\n",
    "                print(\"    Comparison query detected - using AeroFlow for baseline\")\n",
    "                return self.aeroflow_engine.query(query_str)\n",
    "\n",
    "            # Default to alternating\n",
    "            if self.query_count % 2 == 1:\n",
    "                print(\"    Defaulting to AeroFlow (odd query number)\")\n",
    "                return self.aeroflow_engine.query(query_str)\n",
    "            else:\n",
    "                print(\"    Defaulting to EcoSprint (even query number)\")\n",
    "                return self.ecosprint_engine.query(query_str)\n",
    "\n",
    "def create_simple_router():\n",
    "    \"\"\"Create the simple keyword router\"\"\"\n",
    "    if aeroflow_query_engine and ecosprint_query_engine:\n",
    "        return SimpleSmartRouter(aeroflow_query_engine, ecosprint_query_engine)\n",
    "    else:\n",
    "        print(\" Query engines not available\")\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# SOLUTION 3: Hybrid Router with Fallback\n",
    "# ============================================================================\n",
    "\n",
    "class HybridRouter:\n",
    "    \"\"\"Router that tries LLM first, falls back to keywords\"\"\"\n",
    "\n",
    "    def __init__(self, llm_router, keyword_router):\n",
    "        self.llm_router = llm_router\n",
    "        self.keyword_router = keyword_router\n",
    "        self.llm_failures = 0\n",
    "\n",
    "    def query(self, query_str):\n",
    "        \"\"\"Try LLM router first, fallback to keyword router\"\"\"\n",
    "\n",
    "        if self.llm_router and self.llm_failures < 3:\n",
    "            try:\n",
    "                print(\" Trying LLM router...\")\n",
    "                response = self.llm_router.query(query_str)\n",
    "                print(\" LLM router succeeded!\")\n",
    "                return response\n",
    "\n",
    "            except Exception as e:\n",
    "                self.llm_failures += 1\n",
    "                print(f\" LLM router failed ({self.llm_failures}/3): {e}\")\n",
    "                print(\" Falling back to keyword router...\")\n",
    "\n",
    "        # Use keyword router\n",
    "        return self.keyword_router.query(query_str)\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN SETUP\n",
    "# ============================================================================\n",
    "\n",
    "def setup_best_available_router():\n",
    "    \"\"\"Setup the best router that works with your setup\"\"\"\n",
    "\n",
    "    print(\" Setting up best available router...\")\n",
    "\n",
    "    # Try LLM router first\n",
    "    llm_router = create_robust_llm_router()\n",
    "\n",
    "    # Always create keyword router as backup\n",
    "    keyword_router = create_simple_router()\n",
    "\n",
    "    if llm_router and keyword_router:\n",
    "        print(\" Creating hybrid router (LLM + keyword fallback)\")\n",
    "        return HybridRouter(llm_router, keyword_router)\n",
    "    elif keyword_router:\n",
    "        print(\" Using keyword router (reliable fallback)\")\n",
    "        return keyword_router\n",
    "    else:\n",
    "        print(\" No router could be created\")\n",
    "        return None\n",
    "\n",
    "# Create the router\n",
    "print(\"Creating router with best available method...\")\n",
    "router_agent = setup_best_available_router()\n",
    "\n",
    "if router_agent:\n",
    "    print(\" Router setup complete!\")\n",
    "    print(f\"Available tools: AeroFlow_specifications, EcoSprint_specifications\")\n",
    "\n",
    "    # Test the problematic query\n",
    "    print(\"\\n Testing the problematic query...\")\n",
    "    try:\n",
    "        test_query = \"Which vehicle has better performance?\"\n",
    "        response = router_agent.query(test_query)\n",
    "        print(f\"\\n Success! Response preview:\")\n",
    "        preview = str(response)[:200] + \"...\" if len(str(response)) > 200 else str(response)\n",
    "        print(preview)\n",
    "    except Exception as e:\n",
    "        print(f\" Test failed: {e}\")\n",
    "else:\n",
    "    print(\" Router setup failed!\")"
   ],
   "id": "fdad03fa94dfe490",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Agentic Router...\n",
      "Creating router with best available method...\n",
      " Setting up best available router...\n",
      " LLM Router created successfully!\n",
      " Creating hybrid router (LLM + keyword fallback)\n",
      " Router setup complete!\n",
      "Available tools: AeroFlow_specifications, EcoSprint_specifications\n",
      "\n",
      " Testing the problematic query...\n",
      " Trying LLM router...\n",
      " LLM router failed (1/3): Got invalid JSON object. Error: Expecting ',' delimiter: line 6 column 1 (char 424) while parsing a flow sequence\n",
      "  in \"<unicode string>\", line 1, column 1:\n",
      "    [\n",
      "    ^\n",
      "expected ',' or ']', but got '}'\n",
      "  in \"<unicode string>\", line 6, column 1:\n",
      "    }\n",
      "    ^. Got JSON string: [\n",
      "    {\n",
      "        \"choice\": 2,\n",
      "        \"reason\": \"The question asks to compare the performance of two vehicles. Since this tool is specifically designed to provide information about EcoSprint vehicle specifications and their performance metrics, it would be more relevant for answering such a question compared to the tool for AeroFlow which does not have a direct mention of performance comparison in its description.\"\n",
      "    }\n",
      "}\n",
      "]\n",
      " Falling back to keyword router...\n",
      "\n",
      " Router Decision #1\n",
      "Query: 'Which vehicle has better performance?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Comparison query detected - using AeroFlow for baseline\n",
      "\n",
      " Success! Response preview:\n",
      "\n",
      "The provided document does not directly compare two vehicles' performances. It only provides specifications for a single electric family vehicle named AeroFlow. Therefore, it is impossible to determi...\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:09:53.466792Z",
     "start_time": "2025-06-19T05:08:34.000782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper functions for testing\n",
    "def test_various_queries():\n",
    "    \"\"\"Test the router with various queries\"\"\"\n",
    "\n",
    "    if not router_agent:\n",
    "        print(\" No router available\")\n",
    "        return\n",
    "\n",
    "    test_queries = [\n",
    "        \"What colors are available for AeroFlow?\",           # Clear AeroFlow\n",
    "        \"Tell me about EcoSprint battery life\",              # Clear EcoSprint\n",
    "        \"Which vehicle has better performance?\",             # Ambiguous comparison\n",
    "        \"What are the maintenance requirements?\",            # Generic\n",
    "        \"Compare AeroFlow and EcoSprint features\",          # Explicit comparison\n",
    "        \"What is the range of the eco-friendly vehicle?\",   # Contextual EcoSprint\n",
    "    ]\n",
    "\n",
    "    print(\"\\n TESTING VARIOUS QUERIES\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n--- Test {i} ---\")\n",
    "        try:\n",
    "            response = router_agent.query(query)\n",
    "            print(f\" Success! Length: {len(str(response))} chars\")\n",
    "        except Exception as e:\n",
    "            print(f\" Failed: {e}\")\n",
    "\n",
    "print(f\"\\n To test various queries: test_various_queries()\")\n",
    "\n",
    "test_various_queries()"
   ],
   "id": "20ae69152855649c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " To test various queries: test_various_queries()\n",
      "\n",
      " TESTING VARIOUS QUERIES\n",
      "==================================================\n",
      "\n",
      "--- Test 1 ---\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 0: The question is about AeroFlow vehicle specifications, which are covered in option 1. The specific query is about the available colors, which would likely be found under 'design details' or a similar category..\n",
      "\u001B[0m LLM router succeeded!\n",
      " Success! Length: 90 chars\n",
      "\n",
      "--- Test 2 ---\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 1: The question 'Tell me about EcoSprint battery life' is specifically asking for information about the EcoSprint vehicle. According to the given options, this falls under choice 2 which is related to EcoSprint-specific documentation..\n",
      "\u001B[0m LLM router succeeded!\n",
      " Success! Length: 222 chars\n",
      "\n",
      "--- Test 3 ---\n",
      " Trying LLM router...\n",
      " LLM router failed (2/3): Got invalid JSON object. Error: Expecting ',' delimiter: line 6 column 1 (char 424) while parsing a flow sequence\n",
      "  in \"<unicode string>\", line 1, column 1:\n",
      "    [\n",
      "    ^\n",
      "expected ',' or ']', but got '}'\n",
      "  in \"<unicode string>\", line 6, column 1:\n",
      "    }\n",
      "    ^. Got JSON string: [\n",
      "    {\n",
      "        \"choice\": 2,\n",
      "        \"reason\": \"The question asks to compare the performance of two vehicles. Since this tool is specifically designed to provide information about EcoSprint vehicle specifications and their performance metrics, it would be more relevant for answering such a question compared to the tool for AeroFlow which does not have a direct mention of performance comparison in its description.\"\n",
      "    }\n",
      "}\n",
      "]\n",
      " Falling back to keyword router...\n",
      "\n",
      " Router Decision #2\n",
      "Query: 'Which vehicle has better performance?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Comparison query detected - using AeroFlow for baseline\n",
      " Success! Length: 323 chars\n",
      "\n",
      "--- Test 4 ---\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 1: The question 'What are the maintenance requirements?' does not specify a particular vehicle model. However, both options provide information on maintenance procedures, so it is reasonable to choose the one that includes EcoSprint as well, which is option 2..\n",
      "\u001B[0m LLM router succeeded!\n",
      " Success! Length: 168 chars\n",
      "\n",
      "--- Test 5 ---\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 1: The question 'Compare AeroFlow and EcoSprint features' is asking to compare the features of both vehicles. This requires understanding the specifications of both AeroFlow and EcoSprint, which is provided in option 2. Therefore, choice 2 is the most relevant..\n",
      "\u001B[0m LLM router succeeded!\n",
      " Success! Length: 485 chars\n",
      "\n",
      "--- Test 6 ---\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 1: The question specifically asks about the range of an 'eco-friendly' vehicle. While both options provide information on specifications, only option 2 explicitly mentions EcoSprint, which is described as having eco-sprint in its name. Therefore, it is more likely to contain information about the range of an eco-friendly vehicle..\n",
      "\u001B[0m LLM router succeeded!\n",
      " Success! Length: 82 chars\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:14:56.975688Z",
     "start_time": "2025-06-19T05:11:26.923078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comprehensive Router Testing\n",
    "def test_router_intelligence():\n",
    "    \"\"\"Test the router with various query types to see how smart it is\"\"\"\n",
    "\n",
    "    print(\" COMPREHENSIVE ROUTER INTELLIGENCE TEST\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"category\": \" Explicit Vehicle Mentions\",\n",
    "            \"queries\": [\n",
    "                \"What colors are available for AeroFlow?\",\n",
    "                \"Tell me about EcoSprint's battery specifications\",\n",
    "                \"How do I maintain my AeroFlow vehicle?\",\n",
    "                \"What is EcoSprint's top speed?\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \" Ambiguous/Comparison Queries\",\n",
    "            \"queries\": [\n",
    "                \"Which vehicle has better performance?\",\n",
    "                \"What are the available color options?\",\n",
    "                \"Compare the two electric vehicles\",\n",
    "                \"Which one is more environmentally friendly?\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \" Contextual Keywords\",\n",
    "            \"queries\": [\n",
    "                \"Tell me about the eco-friendly features\",  # Should favor EcoSprint\n",
    "                \"What about aerodynamic design?\",            # Should favor AeroFlow\n",
    "                \"How green is this vehicle?\",                # Should favor EcoSprint\n",
    "                \"What about the flow dynamics?\"              # Should favor AeroFlow\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \" Technical Specifications\",\n",
    "            \"queries\": [\n",
    "                \"What is the battery capacity?\",\n",
    "                \"How long does charging take?\",\n",
    "                \"What safety features are included?\",\n",
    "                \"What is the warranty coverage?\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    total_tests = 0\n",
    "    successful_tests = 0\n",
    "\n",
    "    for category_info in test_cases:\n",
    "        category = category_info[\"category\"]\n",
    "        queries = category_info[\"queries\"]\n",
    "\n",
    "        print(f\"\\n{category}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        for i, query in enumerate(queries, 1):\n",
    "            total_tests += 1\n",
    "            print(f\"\\n{i}. Testing: '{query}'\")\n",
    "\n",
    "            try:\n",
    "                response = router_agent.query(query)\n",
    "                successful_tests += 1\n",
    "\n",
    "                # Analyze the response\n",
    "                response_str = str(response).lower()\n",
    "                response_length = len(str(response))\n",
    "\n",
    "                print(f\"    Success! ({response_length} chars)\")\n",
    "\n",
    "                # Determine which document was likely used\n",
    "                if \"aeroflow\" in response_str and \"ecosprint\" not in response_str:\n",
    "                    print(f\"    Routed to: AeroFlow (correct detection)\")\n",
    "                elif \"ecosprint\" in response_str and \"aeroflow\" not in response_str:\n",
    "                    print(f\"    Routed to: EcoSprint (correct detection)\")\n",
    "                elif \"aeroflow\" in response_str and \"ecosprint\" in response_str:\n",
    "                    print(f\"    Both mentioned (comparison or general info)\")\n",
    "                else:\n",
    "                    print(f\"    General response\")\n",
    "\n",
    "                # Show preview\n",
    "                preview = str(response)[:100] + \"...\" if len(str(response)) > 100 else str(response)\n",
    "                print(f\"   Preview: {preview}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    Failed: {e}\")\n",
    "\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\" TEST SUMMARY\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\" Successful: {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)\")\n",
    "    print(f\" Failed: {total_tests - successful_tests}/{total_tests}\")\n",
    "\n",
    "    if successful_tests > total_tests * 0.8:\n",
    "        print(f\" Excellent performance! Router is working very well.\")\n",
    "    elif successful_tests > total_tests * 0.6:\n",
    "        print(f\" Good performance! Router is working adequately.\")\n",
    "    else:\n",
    "        print(f\"  Router needs improvement.\")\n",
    "\n",
    "def analyze_router_behavior():\n",
    "    \"\"\"Analyze how the router makes decisions\"\"\"\n",
    "\n",
    "    print(\"\\n ROUTER BEHAVIOR ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"Current Router Setup:\")\n",
    "    print(f\"  Type: {type(router_agent).__name__}\")\n",
    "\n",
    "    if hasattr(router_agent, 'llm_router'):\n",
    "        print(f\"  LLM Router: {'Available' if router_agent.llm_router else 'Not Available'}\")\n",
    "        print(f\"  LLM Failures: {router_agent.llm_failures}/3\")\n",
    "\n",
    "    if hasattr(router_agent, 'keyword_router'):\n",
    "        print(f\"  Keyword Router: Available\")\n",
    "        if hasattr(router_agent.keyword_router, 'query_count'):\n",
    "            print(f\"  Queries Processed: {router_agent.keyword_router.query_count}\")\n",
    "\n",
    "def show_routing_tips():\n",
    "    \"\"\"Show tips for getting better routing results\"\"\"\n",
    "\n",
    "    print(\"\\n ROUTING OPTIMIZATION TIPS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    tips = [\n",
    "        (\" Be Specific\", \"Include 'AeroFlow' or 'EcoSprint' in your queries\"),\n",
    "        (\" Use Keywords\", \"Words like 'eco', 'green' favor EcoSprint; 'aero', 'flow' favor AeroFlow\"),\n",
    "        (\" For Comparisons\", \"Ask specific comparisons like 'AeroFlow vs EcoSprint battery life'\"),\n",
    "        (\" If Wrong Tool\", \"Rephrase with explicit vehicle name\"),\n",
    "        (\" Test Edge Cases\", \"Try ambiguous queries to see router intelligence\")\n",
    "    ]\n",
    "\n",
    "    for emoji_title, tip in tips:\n",
    "        print(f\"{emoji_title}: {tip}\")\n",
    "\n",
    "def demo_smart_queries():\n",
    "    \"\"\"Demonstrate smart query formulation\"\"\"\n",
    "\n",
    "    print(\"\\n SMART QUERY EXAMPLES\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    examples = [\n",
    "        (\" Generic\", \"What is the battery life?\", \" Specific\", \"What is AeroFlow's battery life?\"),\n",
    "        (\" Ambiguous\", \"Which is better?\", \" Clear\", \"Which has better range, AeroFlow or EcoSprint?\"),\n",
    "        (\" Vague\", \"Tell me about colors\", \" Targeted\", \"What color options does EcoSprint offer?\"),\n",
    "        (\" Unclear\", \"How do I charge it?\", \" Explicit\", \"How do I charge the AeroFlow vehicle?\")\n",
    "    ]\n",
    "\n",
    "    for bad_label, bad_query, good_label, good_query in examples:\n",
    "        print(f\"{bad_label}: '{bad_query}'\")\n",
    "        print(f\"{good_label}: '{good_query}'\")\n",
    "        print()\n",
    "\n",
    "# Run the comprehensive test\n",
    "test_router_intelligence()\n",
    "\n",
    "# Show additional analysis\n",
    "analyze_router_behavior()\n",
    "show_routing_tips()\n",
    "demo_smart_queries()\n",
    "\n",
    "print(f\"\\n Your router is working! The hybrid approach gives you:\")\n",
    "print(f\"   Reliable routing (keyword fallback)\")\n",
    "print(f\"   Smart decisions (comparison detection)\")\n",
    "print(f\"   Clear feedback (shows decision process)\")\n",
    "print(f\"   Automatic fallback (when LLM fails)\")"
   ],
   "id": "73cf725469fc9704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " COMPREHENSIVE ROUTER INTELLIGENCE TEST\n",
      "============================================================\n",
      "\n",
      " Explicit Vehicle Mentions\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Testing: 'What colors are available for AeroFlow?'\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 0: The question is about AeroFlow vehicle specifications, which are covered in option 1. The specific query is about the available colors, which would likely be found under 'design details' or a similar category..\n",
      "\u001B[0m LLM router succeeded!\n",
      "    Success! (90 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview:  The AeroFlow is available in colors such as Coastal Blue, Sunset Orange, and Pearl White.\n",
      "\n",
      "2. Testing: 'Tell me about EcoSprint's battery specifications'\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 1: The question 'Tell me about EcoSprint's battery specifications' is asking for information specifically related to the EcoSprint vehicle. Therefore, choice 2, which is about EcoSprint vehicle specifications including technology components and technical specifications, is most relevant..\n",
      "\u001B[0m LLM router succeeded!\n",
      "    Success! (334 chars)\n",
      "    Routed to: EcoSprint (correct detection)\n",
      "   Preview: \n",
      "The EcoSprint is equipped with a 50 kWh lithium-ion battery. This battery offers an impressive rang...\n",
      "\n",
      "3. Testing: 'How do I maintain my AeroFlow vehicle?'\n",
      " Trying LLM router...\n",
      "\u001B[1;3;38;5;200mSelecting query engine 0: The question 'How do I maintain my AeroFlow vehicle?' is related to a specific vehicle model, the AeroFlow. According to the given options, choice 1 is the most relevant as it specifically mentions using this tool for questions about AeroFlow vehicle specifications, including maintenance procedures..\n",
      "\u001B[0m LLM router succeeded!\n",
      "    Success! (453 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview: \n",
      "To maintain your AeroFlow vehicle, follow the easy-to-follow service schedule designed with low mai...\n",
      "\n",
      "4. Testing: 'What is EcoSprint's top speed?'\n",
      " Trying LLM router...\n",
      " LLM router failed (3/3): Got invalid JSON object. Error: Expecting ',' delimiter: line 6 column 1 (char 331) while parsing a flow sequence\n",
      "  in \"<unicode string>\", line 1, column 1:\n",
      "    [\n",
      "    ^\n",
      "expected ',' or ']', but got '}'\n",
      "  in \"<unicode string>\", line 6, column 1:\n",
      "    }\n",
      "    ^. Got JSON string: [\n",
      "    {\n",
      "        \"choice\": 2,\n",
      "        \"reason\": \"The question specifically asks about EcoSprint's top speed, which is a specification related to the vehicle. According to the provided options, this tool (option 2) is used for questions about EcoSprint vehicle specifications, including performance metrics such as top speed.\"\n",
      "    }\n",
      "}\n",
      "]\n",
      " Falling back to keyword router...\n",
      "\n",
      " Router Decision #3\n",
      "Query: 'What is EcoSprint's top speed?'\n",
      "   + EcoSprint explicitly mentioned (+10)\n",
      "   + EcoSprint keyword 'eco' found (+2)\n",
      "   + EcoSprint keyword 'sprint' found (+2)\n",
      "    Routing to EcoSprint (score: 14 vs 0)\n",
      "    Success! (24 chars)\n",
      "    General response\n",
      "   Preview: 120 mph (miles per hour)\n",
      "\n",
      " Ambiguous/Comparison Queries\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Testing: 'Which vehicle has better performance?'\n",
      "\n",
      " Router Decision #4\n",
      "Query: 'Which vehicle has better performance?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Comparison query detected - using AeroFlow for baseline\n",
      "    Success! (331 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview: \n",
      "The provided specification document does not directly compare two vehicles' performances. It only p...\n",
      "\n",
      "2. Testing: 'What are the available color options?'\n",
      "\n",
      " Router Decision #5\n",
      "Query: 'What are the available color options?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Defaulting to AeroFlow (odd query number)\n",
      "    Success! (90 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview:  The AeroFlow is available in colors such as Coastal Blue, Sunset Orange, and Pearl White.\n",
      "\n",
      "3. Testing: 'Compare the two electric vehicles'\n",
      "\n",
      " Router Decision #6\n",
      "Query: 'Compare the two electric vehicles'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Comparison query detected - using AeroFlow for baseline\n",
      "    Success! (2366 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview: \n",
      "To compare the two electric vehicles, we would need specific details about the second electric vehi...\n",
      "\n",
      "4. Testing: 'Which one is more environmentally friendly?'\n",
      "\n",
      " Router Decision #7\n",
      "Query: 'Which one is more environmentally friendly?'\n",
      "   + EcoSprint keyword 'environment' found (+2)\n",
      "    Routing to EcoSprint (score: 2 vs 0)\n",
      "    Success! (468 chars)\n",
      "    Routed to: EcoSprint (correct detection)\n",
      "   Preview:  The EcoSprint electric vehicle (EV) is more environmentally friendly compared to traditional gasoli...\n",
      "\n",
      " Contextual Keywords\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Testing: 'Tell me about the eco-friendly features'\n",
      "\n",
      " Router Decision #8\n",
      "Query: 'Tell me about the eco-friendly features'\n",
      "   + EcoSprint keyword 'eco' found (+2)\n",
      "    Routing to EcoSprint (score: 2 vs 0)\n",
      "    Success! (765 chars)\n",
      "    Routed to: EcoSprint (correct detection)\n",
      "   Preview: \n",
      "The EcoSprint is a revolutionary electric vehicle designed with efficiency in mind. It boasts an im...\n",
      "\n",
      "2. Testing: 'What about aerodynamic design?'\n",
      "\n",
      " Router Decision #9\n",
      "Query: 'What about aerodynamic design?'\n",
      "   + AeroFlow keyword 'aero' found (+2)\n",
      "   + AeroFlow keyword 'aerodynamic' found (+2)\n",
      "    Routing to AeroFlow (score: 4 vs 0)\n",
      "    Success! (274 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview: \n",
      "The provided specification document does not mention any details about the AeroFlow's aerodynamic d...\n",
      "\n",
      "3. Testing: 'How green is this vehicle?'\n",
      "\n",
      " Router Decision #10\n",
      "Query: 'How green is this vehicle?'\n",
      "   + EcoSprint keyword 'green' found (+2)\n",
      "    Routing to EcoSprint (score: 2 vs 0)\n",
      "    Success! (690 chars)\n",
      "    Routed to: EcoSprint (correct detection)\n",
      "   Preview: \n",
      "The EcoSprint is a revolutionary electric vehicle designed for efficiency and performance, appealin...\n",
      "\n",
      "4. Testing: 'What about the flow dynamics?'\n",
      "\n",
      " Router Decision #11\n",
      "Query: 'What about the flow dynamics?'\n",
      "   + AeroFlow keyword 'flow' found (+2)\n",
      "    Routing to AeroFlow (score: 2 vs 0)\n",
      "    Success! (480 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview: \n",
      "The provided specification document does not mention any details about \"flow dynamics.\" The documen...\n",
      "\n",
      " Technical Specifications\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Testing: 'What is the battery capacity?'\n",
      "\n",
      " Router Decision #12\n",
      "Query: 'What is the battery capacity?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Defaulting to EcoSprint (even query number)\n",
      "    Success! (26 chars)\n",
      "    General response\n",
      "   Preview: 50 kWh lithium-ion battery\n",
      "\n",
      "2. Testing: 'How long does charging take?'\n",
      "\n",
      " Router Decision #13\n",
      "Query: 'How long does charging take?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Defaulting to AeroFlow (odd query number)\n",
      "    Success! (295 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview: \n",
      "The provided specification document does not mention the specific time it takes to charge the AeroF...\n",
      "\n",
      "3. Testing: 'What safety features are included?'\n",
      "\n",
      " Router Decision #14\n",
      "Query: 'What safety features are included?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Defaulting to EcoSprint (even query number)\n",
      "    Success! (123 chars)\n",
      "    Routed to: EcoSprint (correct detection)\n",
      "   Preview:  The EcoSprint includes high-rated safety features such as multiple airbags, a reinforced frame, and...\n",
      "\n",
      "4. Testing: 'What is the warranty coverage?'\n",
      "\n",
      " Router Decision #15\n",
      "Query: 'What is the warranty coverage?'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Defaulting to AeroFlow (odd query number)\n",
      "    Success! (144 chars)\n",
      "    Routed to: AeroFlow (correct detection)\n",
      "   Preview:  The AeroFlow comes with a comprehensive warranty of 7 years or 70,000 miles, whichever comes first,...\n",
      "\n",
      "============================================================\n",
      " TEST SUMMARY\n",
      "============================================================\n",
      " Successful: 16/16 (100.0%)\n",
      " Failed: 0/16\n",
      " Excellent performance! Router is working very well.\n",
      "\n",
      " ROUTER BEHAVIOR ANALYSIS\n",
      "==================================================\n",
      "Current Router Setup:\n",
      "  Type: HybridRouter\n",
      "  LLM Router: Available\n",
      "  LLM Failures: 3/3\n",
      "  Keyword Router: Available\n",
      "  Queries Processed: 15\n",
      "\n",
      " ROUTING OPTIMIZATION TIPS\n",
      "==================================================\n",
      " Be Specific: Include 'AeroFlow' or 'EcoSprint' in your queries\n",
      " Use Keywords: Words like 'eco', 'green' favor EcoSprint; 'aero', 'flow' favor AeroFlow\n",
      " For Comparisons: Ask specific comparisons like 'AeroFlow vs EcoSprint battery life'\n",
      " If Wrong Tool: Rephrase with explicit vehicle name\n",
      " Test Edge Cases: Try ambiguous queries to see router intelligence\n",
      "\n",
      " SMART QUERY EXAMPLES\n",
      "==================================================\n",
      " Generic: 'What is the battery life?'\n",
      " Specific: 'What is AeroFlow's battery life?'\n",
      "\n",
      " Ambiguous: 'Which is better?'\n",
      " Clear: 'Which has better range, AeroFlow or EcoSprint?'\n",
      "\n",
      " Vague: 'Tell me about colors'\n",
      " Targeted: 'What color options does EcoSprint offer?'\n",
      "\n",
      " Unclear: 'How do I charge it?'\n",
      " Explicit: 'How do I charge the AeroFlow vehicle?'\n",
      "\n",
      "\n",
      " Your router is working! The hybrid approach gives you:\n",
      "   Reliable routing (keyword fallback)\n",
      "   Smart decisions (comparison detection)\n",
      "   Clear feedback (shows decision process)\n",
      "   Automatic fallback (when LLM fails)\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d7a7c0e6fcf52639"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:24:34.677638Z",
     "start_time": "2025-06-19T05:24:34.665996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_router_comprehensive():\n",
    "    \"\"\"Comprehensive test function with better test queries\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" COMPREHENSIVE ROUTER TESTING\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Test cases with clear expected routing\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"query\": \"What are the key features of AeroFlow?\",\n",
    "            \"expected_tool\": \"AeroFlow_specifications\",\n",
    "            \"description\": \"Should route to AeroFlow tool\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Tell me about EcoSprint's battery specifications\",\n",
    "            \"expected_tool\": \"EcoSprint_specifications\",\n",
    "            \"description\": \"Should route to EcoSprint tool\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What is the warranty coverage for AeroFlow vehicles?\",\n",
    "            \"expected_tool\": \"AeroFlow_specifications\",\n",
    "            \"description\": \"AeroFlow warranty question\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"How do I maintain an EcoSprint?\",\n",
    "            \"expected_tool\": \"EcoSprint_specifications\",\n",
    "            \"description\": \"EcoSprint maintenance question\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Compare the design features of both vehicles\",\n",
    "            \"expected_tool\": \"Either (ambiguous)\",\n",
    "            \"description\": \"Ambiguous query - could go to either\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n--- Test {i}: {test_case['description']} ---\")\n",
    "        print(f\"Query: '{test_case['query']}'\")\n",
    "        print(f\"Expected routing: {test_case['expected_tool']}\")\n",
    "\n",
    "        try:\n",
    "            # Capture the response\n",
    "            response = router_agent.query(test_case['query'])\n",
    "\n",
    "            # Try to determine which tool was actually used\n",
    "            # (This is tricky since we need to parse the verbose output)\n",
    "            print(f\"Response preview: {str(response)[:200]}...\")\n",
    "\n",
    "            results.append({\n",
    "                \"test\": i,\n",
    "                \"query\": test_case['query'],\n",
    "                \"success\": True,\n",
    "                \"response\": str(response)\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Test failed: {e}\")\n",
    "            results.append({\n",
    "                \"test\": i,\n",
    "                \"query\": test_case['query'],\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\" TEST SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    successful_tests = [r for r in results if r[\"success\"]]\n",
    "    print(f\" Successful tests: {len(successful_tests)}/{len(results)}\")\n",
    "\n",
    "    if len(successful_tests) < len(results):\n",
    "        failed_tests = [r for r in results if not r[\"success\"]]\n",
    "        print(f\" Failed tests: {len(failed_tests)}\")\n",
    "        for test in failed_tests:\n",
    "            print(f\"   - Test {test['test']}: {test['error']}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_simple_routing():\n",
    "    \"\"\"Simple test to verify basic routing functionality\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" SIMPLE ROUTING TEST\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Simple, clear test queries\n",
    "    simple_tests = [\n",
    "        (\"What are the key features of AeroFlow?\", \"Should route to AeroFlow\"),\n",
    "        (\"What are the specifications of EcoSprint?\", \"Should route to EcoSprint\"),\n",
    "        (\"Tell me about AeroFlow's battery\", \"Should route to AeroFlow\"),\n",
    "        (\"How do I maintain EcoSprint?\", \"Should route to EcoSprint\")\n",
    "    ]\n",
    "\n",
    "    for query, expected in simple_tests:\n",
    "        print(f\"\\n--- Testing: '{query}' ---\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "\n",
    "        try:\n",
    "            print(\"Router is thinking...\")\n",
    "            response = router_agent.query(query)\n",
    "\n",
    "            print(f\" Got response! Length: {len(str(response))} characters\")\n",
    "\n",
    "            # Show first 200 characters of response\n",
    "            preview = str(response)[:200] + \"...\" if len(str(response)) > 200 else str(response)\n",
    "            print(f\"Response preview: {preview}\")\n",
    "\n",
    "            # Simple check if response seems relevant\n",
    "            response_lower = str(response).lower()\n",
    "            if \"aeroflow\" in query.lower() and \"aeroflow\" in response_lower:\n",
    "                print(\" Response mentions AeroFlow - likely correct routing\")\n",
    "            elif \"ecosprint\" in query.lower() and \"ecosprint\" in response_lower:\n",
    "                print(\" Response mentions EcoSprint - likely correct routing\")\n",
    "            elif len(str(response)) > 50:\n",
    "                print(\"  Got substantial response - router seems to be working\")\n",
    "            else:\n",
    "                print(\"  Short response - might need investigation\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error: {e}\")\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "def analyze_router_behavior():\n",
    "    \"\"\"Analyze what the router is actually doing\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\" ROUTER BEHAVIOR ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(f\"Router type: {type(router_agent).__name__}\")\n",
    "\n",
    "    # Try to access selector safely\n",
    "    try:\n",
    "        if hasattr(router_agent, '_selector'):\n",
    "            print(f\"Selector type: {type(router_agent._selector).__name__}\")\n",
    "        elif hasattr(router_agent, 'selector'):\n",
    "            print(f\"Selector type: {type(router_agent.selector).__name__}\")\n",
    "        else:\n",
    "            print(\"Selector type: Not directly accessible\")\n",
    "    except:\n",
    "        print(\"Selector type: Could not determine\")\n",
    "\n",
    "    # Check tools\n",
    "    try:\n",
    "        if hasattr(router_agent, 'query_engine_tools'):\n",
    "            print(f\"Number of tools: {len(router_agent.query_engine_tools)}\")\n",
    "\n",
    "            print(\"\\nTool details:\")\n",
    "            for i, tool in enumerate(router_agent.query_engine_tools):\n",
    "                print(f\"  {i}: {tool.metadata.name}\")\n",
    "                print(f\"     Description: {tool.metadata.description[:100]}...\")\n",
    "        else:\n",
    "            print(\"Tools: Not directly accessible\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing tools: {e}\")\n",
    "\n",
    "    # Show router attributes\n",
    "    print(f\"\\nRouter attributes: {[attr for attr in dir(router_agent) if not attr.startswith('_')]}\")\n",
    "\n",
    "# Choose which test to run\n",
    "def run_router_tests(test_type=\"simple\"):\n",
    "    \"\"\"\n",
    "    Run router tests\n",
    "\n",
    "    Args:\n",
    "        test_type: \"simple\", \"comprehensive\", or \"analyze\"\n",
    "    \"\"\"\n",
    "\n",
    "    if test_type == \"simple\":\n",
    "        test_simple_routing()\n",
    "    elif test_type == \"comprehensive\":\n",
    "        test_router_comprehensive()\n",
    "    elif test_type == \"analyze\":\n",
    "        analyze_router_behavior()\n",
    "    else:\n",
    "        print(\"Available test types: 'simple', 'comprehensive', 'analyze'\")\n"
   ],
   "id": "e19a405cd69ffbe5",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:24:36.290970Z",
     "start_time": "2025-06-19T05:24:36.288206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run basic analysis first\n",
    "analyze_router_behavior()\n",
    "\n",
    "print(\"\\n To test the router, run:\")\n",
    "print(\"   run_router_tests('simple')      # Basic functionality test\")\n",
    "print(\"   run_router_tests('comprehensive') # Detailed routing test\")\n",
    "print(\"   run_router_tests('analyze')     # Router configuration analysis\")"
   ],
   "id": "549fff201361d5f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " ROUTER BEHAVIOR ANALYSIS\n",
      "==================================================\n",
      "Router type: HybridRouter\n",
      "Selector type: Not directly accessible\n",
      "Tools: Not directly accessible\n",
      "\n",
      "Router attributes: ['keyword_router', 'llm_failures', 'llm_router', 'query']\n",
      "\n",
      " To test the router, run:\n",
      "   run_router_tests('simple')      # Basic functionality test\n",
      "   run_router_tests('comprehensive') # Detailed routing test\n",
      "   run_router_tests('analyze')     # Router configuration analysis\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T05:25:40.020151Z",
     "start_time": "2025-06-19T05:24:39.588313Z"
    }
   },
   "cell_type": "code",
   "source": "run_router_tests('comprehensive')",
   "id": "68865ff4149cfff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " COMPREHENSIVE ROUTER TESTING\n",
      "======================================================================\n",
      "\n",
      "--- Test 1: Should route to AeroFlow tool ---\n",
      "Query: 'What are the key features of AeroFlow?'\n",
      "Expected routing: AeroFlow_specifications\n",
      "\n",
      " Router Decision #16\n",
      "Query: 'What are the key features of AeroFlow?'\n",
      "   + AeroFlow explicitly mentioned (+10)\n",
      "   + AeroFlow keyword 'aero' found (+2)\n",
      "   + AeroFlow keyword 'flow' found (+2)\n",
      "    Routing to AeroFlow (score: 14 vs 0)\n",
      "Response preview: \n",
      "The key features of AeroFlow include a sleek, modern exterior design with a spacious interior layout, available in colors like Coastal Blue, Sunset Orange, and Pearl White. The interior boasts a vers...\n",
      "\n",
      "--- Test 2: Should route to EcoSprint tool ---\n",
      "Query: 'Tell me about EcoSprint's battery specifications'\n",
      "Expected routing: EcoSprint_specifications\n",
      "\n",
      " Router Decision #17\n",
      "Query: 'Tell me about EcoSprint's battery specifications'\n",
      "   + EcoSprint explicitly mentioned (+10)\n",
      "   + EcoSprint keyword 'eco' found (+2)\n",
      "   + EcoSprint keyword 'sprint' found (+2)\n",
      "    Routing to EcoSprint (score: 14 vs 0)\n",
      "Response preview:  The EcoSprint is equipped with a 50 kWh lithium-ion battery. This battery offers an impressive range of up to 250 miles on a single charge. Charging the vehicle can be conveniently done at home with ...\n",
      "\n",
      "--- Test 3: AeroFlow warranty question ---\n",
      "Query: 'What is the warranty coverage for AeroFlow vehicles?'\n",
      "Expected routing: AeroFlow_specifications\n",
      "\n",
      " Router Decision #18\n",
      "Query: 'What is the warranty coverage for AeroFlow vehicles?'\n",
      "   + AeroFlow explicitly mentioned (+10)\n",
      "   + AeroFlow keyword 'aero' found (+2)\n",
      "   + AeroFlow keyword 'flow' found (+2)\n",
      "    Routing to AeroFlow (score: 14 vs 0)\n",
      "Response preview: 7-year/70,000-mile comprehensive warranty and an 8-year/90,000-mile battery warranty....\n",
      "\n",
      "--- Test 4: EcoSprint maintenance question ---\n",
      "Query: 'How do I maintain an EcoSprint?'\n",
      "Expected routing: EcoSprint_specifications\n",
      "\n",
      " Router Decision #19\n",
      "Query: 'How do I maintain an EcoSprint?'\n",
      "   + EcoSprint explicitly mentioned (+10)\n",
      "   + EcoSprint keyword 'eco' found (+2)\n",
      "   + EcoSprint keyword 'sprint' found (+2)\n",
      "    Routing to EcoSprint (score: 14 vs 0)\n",
      "Response preview: \n",
      "To maintain an EcoSprint, you should follow these guidelines:\n",
      "1. Regular Maintenance: The EcoSprint has low maintenance requirements with recommended checks every 10,000 miles. You can easily schedul...\n",
      "\n",
      "--- Test 5: Ambiguous query - could go to either ---\n",
      "Query: 'Compare the design features of both vehicles'\n",
      "Expected routing: Either (ambiguous)\n",
      "\n",
      " Router Decision #20\n",
      "Query: 'Compare the design features of both vehicles'\n",
      "    Ambiguous query (both scored 0)\n",
      "    Comparison query detected - using AeroFlow for baseline\n",
      "Response preview: \n",
      "The provided document does not contain specifications for two different vehicles to compare their design features. It only provides detailed specifications for a single electric vehicle named AeroFlo...\n",
      "\n",
      "==================================================\n",
      " TEST SUMMARY\n",
      "==================================================\n",
      " Successful tests: 5/5\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 03.05. Route with Agentic AI",
   "id": "02d4e35b-73ad-4692-9218-d751f6baa9c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;3;38;5;200mSelecting query engine 0: The question is about AeroFlow vehicle specifications, which are covered in option 1. The specific query is about the available colors, which would likely be found under 'design details' or a similar category..\n",
      "\u001B[0m\n",
      "Response:   The AeroFlow is available in colors such as Coastal Blue, Sunset Orange, and Pearl White.\n"
     ]
    }
   ],
   "execution_count": 19,
   "source": [
    "#Ask a question about NoSQL\n",
    "response = router_agent.query(\"What colors are available for AeroFlow?\")\n",
    "print(\"\\nResponse: \",str(response))"
   ],
   "id": "429aea8c-f8ae-4a52-8a50-0da4c082fb68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;3;38;5;200mSelecting query engine 1: The question 'What colors are available for EcoSprint?' is asking about specifications related to the EcoSprint vehicle. According to the given options, using this tool for questions about EcoSprint vehicle specifications, including design details, features, technology components, maintenance procedures, warranty information, performance metrics, and technical specifications (option 2) is most relevant..\n",
      "\u001B[0m\n",
      "Response:   The EcoSprint is available in Midnight Black, Ocean Blue, and Pearl White.\n"
     ]
    }
   ],
   "execution_count": 20,
   "source": [
    "response = router_agent.query(\"What colors are available for EcoSprint?\")\n",
    "print(\"\\nResponse: \",str(response))"
   ],
   "id": "a0cd1078-a27f-4e3e-b3f6-b98a0d66027e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 21,
   "source": "# Inspect Indexes and Vector Stores",
   "id": "1c2f3f20-8738-4a7d-90d3-5db595298dac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:12:06.921078Z",
     "start_time": "2025-06-19T04:12:06.917236Z"
    }
   },
   "cell_type": "code",
   "source": "run_full_inspection()",
   "id": "4fed135c736f968",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " VECTOR INDEX INSPECTION REPORT\n",
      "================================================================================\n",
      "Generated at: 2025-06-18 23:12:06\n",
      "\n",
      " INDEX STORAGE LOCATIONS\n",
      "----------------------------------------\n",
      "Current working directory: /Users/jarotball/Setups/agentic-ai-for-developers-concepts-and-applications-for-enterprises-3913172\n",
      "No storage found at: ./storage\n",
      "No storage found at: ./index_storage\n",
      "No storage found at: ./vector_store\n",
      "\n",
      " Note: By default, VectorStoreIndex stores data in memory.\n",
      "   To persist indexes, you'd need to use index.storage_context.persist()\n",
      "\n",
      "============================================================\n",
      " AEROFLOW INDEX ANALYSIS\n",
      "============================================================\n",
      "\n",
      " AeroFlow INDEX OVERVIEW\n",
      "------------------------------\n",
      "Total nodes: 2\n",
      "Vector store type: SimpleVectorStore\n",
      "Vector store client: NoneType\n",
      "Stored vectors: 2\n",
      "\n",
      " AeroFlow NODE CONTENT ANALYSIS\n",
      "-----------------------------------\n",
      "Average chunk size: 1239 characters\n",
      "Min chunk size: 262 characters\n",
      "Max chunk size: 2216 characters\n",
      "\n",
      " SAMPLE CHUNKS FROM AeroFlow\n",
      "------------------------------\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Node ID: 6bb81dce-7322-4d1e-98e3-35e6b0006e23\n",
      "Length: 2216 characters\n",
      "Metadata: {'page_label': '1', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "AeroFlow\n",
      "Detailed\n",
      "Specification\n",
      "Document\n",
      "1.\n",
      "Overview\n",
      "\n",
      "AeroFlow\n",
      "is\n",
      "the\n",
      "ideal\n",
      "family\n",
      "electric\n",
      "vehicle,\n",
      "balancing\n",
      "space,\n",
      "comfort,\n",
      "and\n",
      "efficiency.\n",
      "Designed\n",
      "with\n",
      "family\n",
      "needs\n",
      "in\n",
      "mind,\n",
      "it\n",
      "offers\n",
      "a\n",
      "safe,\n",
      "sp...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Node ID: b6800d9f-2f11-4e04-bb45-f55367ff9d87\n",
      "Length: 262 characters\n",
      "Metadata: {'page_label': '2', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "7.\n",
      "Pricing\n",
      "and\n",
      "Models\n",
      "\n",
      "Pricing\n",
      "Structure:\n",
      "Starts\n",
      "at\n",
      "an\n",
      "accessible\n",
      "price\n",
      "point\n",
      "of\n",
      "$40,000,\n",
      "offering\n",
      "excellent\n",
      "value\n",
      "for\n",
      "a\n",
      "family\n",
      "vehicle.\n",
      "\n",
      "Model\n",
      "Variants:\n",
      "Available\n",
      "in\n",
      "Basic,\n",
      "Comfort,\n",
      "and\n",
      "Luxury\n",
      "edit...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "============================================================\n",
      " ECOSPRINT INDEX ANALYSIS\n",
      "============================================================\n",
      "\n",
      " EcoSprint INDEX OVERVIEW\n",
      "------------------------------\n",
      "Total nodes: 2\n",
      "Vector store type: SimpleVectorStore\n",
      "Vector store client: NoneType\n",
      "Stored vectors: 2\n",
      "\n",
      " EcoSprint NODE CONTENT ANALYSIS\n",
      "-----------------------------------\n",
      "Average chunk size: 1396 characters\n",
      "Min chunk size: 624 characters\n",
      "Max chunk size: 2167 characters\n",
      "\n",
      " SAMPLE CHUNKS FROM EcoSprint\n",
      "------------------------------\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Node ID: e83436e9-ad22-40f7-ae57-14a91fef777b\n",
      "Length: 2167 characters\n",
      "Metadata: {'page_label': '1', 'file_name': 'EcoSprint_Specification_Document.pdf', 'file_path': 'EcoSprint_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 38110, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "EcoSprint\n",
      "Specification\n",
      "Document\n",
      "1.\n",
      "Overview\n",
      "\n",
      "The\n",
      "EcoSprint\n",
      "is\n",
      "a\n",
      "revolutionary\n",
      "electric\n",
      "vehicle\n",
      "(EV)\n",
      "designed\n",
      "for\n",
      "efficiency\n",
      "and\n",
      "performance.\n",
      "With\n",
      "its\n",
      "sleek\n",
      "design\n",
      "and\n",
      "state-of-the-art\n",
      "technology,\n",
      "th...\n",
      "Embedding: Not stored in node\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Node ID: 6def2352-0057-4ce6-b30a-9572e7b193ec\n",
      "Length: 624 characters\n",
      "Metadata: {'page_label': '2', 'file_name': 'EcoSprint_Specification_Document.pdf', 'file_path': 'EcoSprint_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 38110, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}\n",
      "Content preview:\n",
      "6.\n",
      "Maintenance\n",
      "and\n",
      "Warranty\n",
      "\n",
      "Regular\n",
      "Maintenance:\n",
      "Low\n",
      "maintenance\n",
      "requirements\n",
      "with\n",
      "recommended\n",
      "checks\n",
      "every\n",
      "10,000\n",
      "miles.\n",
      "Easy\n",
      "scheduling\n",
      "of\n",
      "service\n",
      "appointments\n",
      "through\n",
      "the\n",
      "mobile\n",
      "app.\n",
      "\n",
      "Warranty:\n",
      "...\n",
      "Embedding: Not stored in node\n",
      "\n",
      " SAVING INDEX CONTENTS TO FILES\n",
      "----------------------------------------\n",
      " AeroFlow chunks saved to: aeroflow_chunks_20250618_231206.txt\n",
      " EcoSprint chunks saved to: ecosprint_chunks_20250618_231206.txt\n",
      "\n",
      " AEROFLOW EMBEDDINGS\n",
      "\n",
      " EMBEDDING VECTOR ANALYSIS\n",
      "-----------------------------------\n",
      "Embedding dimension: 384\n",
      "Sample size: 2\n",
      "Mean value: -0.001544\n",
      "Std deviation: 0.051008\n",
      "Min value: -0.137559\n",
      "Max value: 0.155384\n",
      "\n",
      " ECOSPRINT EMBEDDINGS\n",
      "\n",
      " EMBEDDING VECTOR ANALYSIS\n",
      "-----------------------------------\n",
      "Embedding dimension: 384\n",
      "Sample size: 2\n",
      "Mean value: -0.000305\n",
      "Std deviation: 0.051030\n",
      "Min value: -0.180898\n",
      "Max value: 0.171049\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48c9f1289466d29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Demonstarate the usage of the router in a real-world scenario",
   "id": "d634f862c9dcace0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:47:25.538063Z",
     "start_time": "2025-06-19T04:47:25.530983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Understanding Router Decision Process\n",
    "\"\"\"\n",
    "How the Router Agent Decides Which Tool to Choose\n",
    "================================================\n",
    "\n",
    "The LLMSingleSelector follows this process:\n",
    "\n",
    "1. RECEIVES USER QUERY\n",
    "    \"What colors are available for AeroFlow?\"\n",
    "\n",
    "2. ANALYZES AVAILABLE TOOLS\n",
    "    Tool 0: AeroFlow_specifications\n",
    "       Description: \"Use this tool for questions about AeroFlow vehicle\n",
    "          specifications, including: design details, features, technology\n",
    "          components, maintenance procedures, warranty information,\n",
    "          performance metrics, and technical specifications.\"\n",
    "   \n",
    "    Tool 1: EcoSprint_specifications\n",
    "        Description: \"Use this tool for questions about EcoSprint vehicle\n",
    "           specifications, including: design details, features, technology\n",
    "           components, maintenance procedures, warranty information,\n",
    "           performance metrics, and technical specifications.\"\n",
    "\n",
    "3. LLM REASONING PROCESS\n",
    "   The LLM (DeepSeek Coder) analyzes:\n",
    "    Query contains \"AeroFlow\"  Strong match with Tool 0\n",
    "    Query about \"colors\"  Likely in design/features section\n",
    "    Tool 0 description mentions \"design details, features\"\n",
    "    Tool 1 is about EcoSprint, not AeroFlow\n",
    "\n",
    "4. DECISION\n",
    "    Selects Tool 0 (AeroFlow_specifications)\n",
    "\n",
    "5. EXECUTION\n",
    "    Queries the AeroFlow vector index for color information\n",
    "\"\"\"\n",
    "\n",
    "def demonstrate_router_decision_process():\n",
    "    \"\"\"\n",
    "    Demonstrate and visualize the router decision process\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" ROUTER DECISION PROCESS DEMONSTRATION\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Example queries and expected routing\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"query\": \"What colors are available for AeroFlow?\",\n",
    "            \"key_words\": [\"AeroFlow\", \"colors\"],\n",
    "            \"expected_tool\": \"AeroFlow_specifications\",\n",
    "            \"reasoning\": \"Query mentions 'AeroFlow' specifically, and colors are part of design features\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Tell me about EcoSprint battery life\",\n",
    "            \"key_words\": [\"EcoSprint\", \"battery\"],\n",
    "            \"expected_tool\": \"EcoSprint_specifications\",\n",
    "            \"reasoning\": \"Query mentions 'EcoSprint' specifically, battery is a technical specification\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Which vehicle has better performance?\",\n",
    "            \"key_words\": [\"vehicle\", \"performance\"],\n",
    "            \"expected_tool\": \"Either (ambiguous)\",\n",
    "            \"reasoning\": \"Doesn't mention specific vehicle, LLM must choose based on context\"\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"How do I maintain my electric vehicle?\",\n",
    "            \"key_words\": [\"maintain\", \"electric vehicle\"],\n",
    "            \"expected_tool\": \"Either (ambiguous)\",\n",
    "            \"reasoning\": \"Generic question, could apply to both vehicles\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(\" ROUTING ANALYSIS:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    for i, case in enumerate(test_cases, 1):\n",
    "        print(f\"\\n{i}. Query: '{case['query']}'\")\n",
    "        print(f\"   Key words: {case['key_words']}\")\n",
    "        print(f\"   Expected routing: {case['expected_tool']}\")\n",
    "        print(f\"   Reasoning: {case['reasoning']}\")\n",
    "\n",
    "def show_actual_router_prompt():\n",
    "    \"\"\"\n",
    "    Show what prompt the LLM actually receives for routing decisions\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n ACTUAL LLM PROMPT FOR ROUTING\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # This is approximately what the LLM sees\n",
    "    sample_prompt = \"\"\"\n",
    "You are a query router. Given a user query and a list of tools, select the most appropriate tool.\n",
    "\n",
    "Query: \"What colors are available for AeroFlow?\"\n",
    "\n",
    "Available Tools:\n",
    "0. AeroFlow_specifications\n",
    "   Description: Use this tool for questions about AeroFlow vehicle specifications, including: design details, features, technology components, maintenance procedures, warranty information, performance metrics, and technical specifications. This covers all AeroFlow-related documentation.\n",
    "\n",
    "1. EcoSprint_specifications\n",
    "   Description: Use this tool for questions about EcoSprint vehicle specifications, including: design details, features, technology components, maintenance procedures, warranty information, performance metrics, and technical specifications. This covers all EcoSprint-related documentation.\n",
    "\n",
    "Select the most appropriate tool and explain your reasoning.\n",
    "\"\"\"\n",
    "\n",
    "    print(sample_prompt)\n",
    "\n",
    "    print(\"\\n LLM REASONING OUTPUT:\")\n",
    "    print(\"-\" * 30)\n",
    "    sample_reasoning = \"\"\"\n",
    "    The query asks about \"colors available for AeroFlow\", which specifically mentions AeroFlow.\n",
    "\n",
    "    Tool 0 (AeroFlow_specifications) is designed for AeroFlow-related questions and includes\n",
    "    \"design details\" and \"features\" in its description. Colors would fall under design details.\n",
    "\n",
    "    Tool 1 (EcoSprint_specifications) is for EcoSprint-related questions, which doesn't match\n",
    "    this query about AeroFlow.\n",
    "\n",
    "    Therefore, I select Tool 0.\n",
    "    \"\"\"\n",
    "\n",
    "    print(sample_reasoning)\n",
    "\n",
    "def test_router_with_explanation(query):\n",
    "    \"\"\"\n",
    "    Test the router and show the decision process\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n TESTING ROUTER DECISION\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print()\n",
    "\n",
    "    # Capture the verbose output to see reasoning\n",
    "    import io\n",
    "    import sys\n",
    "    from contextlib import redirect_stdout\n",
    "\n",
    "    print(\" Router is thinking...\")\n",
    "\n",
    "    # The verbose=True in your router will show the reasoning\n",
    "    # Let's capture and display it more clearly\n",
    "\n",
    "    f = io.StringIO()\n",
    "    try:\n",
    "        with redirect_stdout(f):\n",
    "            response = router_agent.query(query)\n",
    "\n",
    "        # Get the captured output\n",
    "        verbose_output = f.getvalue()\n",
    "\n",
    "        print(\" LLM Reasoning Process:\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # Parse and display the reasoning\n",
    "        lines = verbose_output.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip():\n",
    "                if \"Selecting query engine\" in line:\n",
    "                    print(f\" {line}\")\n",
    "                else:\n",
    "                    print(f\"   {line}\")\n",
    "\n",
    "        print(f\"\\n Final Response:\")\n",
    "        print(f\"   Length: {len(str(response))} characters\")\n",
    "        preview = str(response)[:200] + \"...\" if len(str(response)) > 200 else str(response)\n",
    "        print(f\"   Preview: {preview}\")\n",
    "\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error during routing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Key factors that influence routing decisions\n",
    "def explain_routing_factors():\n",
    "    \"\"\"\n",
    "    Explain what factors influence the router's decision\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n KEY FACTORS IN ROUTING DECISIONS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    factors = [\n",
    "        (\"Exact Name Match\", \"Query contains 'AeroFlow' or 'EcoSprint'\", \" Very High\"),\n",
    "        (\"Keyword Relevance\", \"Technical terms match tool descriptions\", \" High\"),\n",
    "        (\"Context Clues\", \"Related terms suggest specific domain\", \" Medium\"),\n",
    "        (\"Tool Descriptions\", \"How well query aligns with tool purpose\", \" Medium\"),\n",
    "        (\"LLM Training\", \"Model's understanding of relationships\", \" Background\")\n",
    "    ]\n",
    "\n",
    "    print(f\"{'Factor':<20} {'Description':<40} {'Influence':<15}\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "    for factor, description, influence in factors:\n",
    "        print(f\"{factor:<20} {description:<40} {influence:<15}\")\n",
    "\n",
    "    print(f\"\\n Pro Tips for Better Routing:\")\n",
    "    print(f\" Use specific vehicle names in your queries\")\n",
    "    print(f\" Include relevant technical terms\")\n",
    "    print(f\" Be specific rather than generic\")\n",
    "    print(f\" Test edge cases to understand behavior\")\n",
    "\n",
    "# Run demonstrations\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_router_decision_process()\n",
    "    show_actual_router_prompt()\n",
    "    explain_routing_factors()\n",
    "\n",
    "    print(f\"\\n To test with your actual router:\")\n",
    "    print(f'   test_router_with_explanation(\"What colors are available for AeroFlow?\")')"
   ],
   "id": "7d6d2c4b423a8125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ROUTER DECISION PROCESS DEMONSTRATION\n",
      "============================================================\n",
      " ROUTING ANALYSIS:\n",
      "----------------------------------------\n",
      "\n",
      "1. Query: 'What colors are available for AeroFlow?'\n",
      "   Key words: ['AeroFlow', 'colors']\n",
      "   Expected routing: AeroFlow_specifications\n",
      "   Reasoning: Query mentions 'AeroFlow' specifically, and colors are part of design features\n",
      "\n",
      "2. Query: 'Tell me about EcoSprint battery life'\n",
      "   Key words: ['EcoSprint', 'battery']\n",
      "   Expected routing: EcoSprint_specifications\n",
      "   Reasoning: Query mentions 'EcoSprint' specifically, battery is a technical specification\n",
      "\n",
      "3. Query: 'Which vehicle has better performance?'\n",
      "   Key words: ['vehicle', 'performance']\n",
      "   Expected routing: Either (ambiguous)\n",
      "   Reasoning: Doesn't mention specific vehicle, LLM must choose based on context\n",
      "\n",
      "4. Query: 'How do I maintain my electric vehicle?'\n",
      "   Key words: ['maintain', 'electric vehicle']\n",
      "   Expected routing: Either (ambiguous)\n",
      "   Reasoning: Generic question, could apply to both vehicles\n",
      "\n",
      " ACTUAL LLM PROMPT FOR ROUTING\n",
      "==================================================\n",
      "\n",
      "You are a query router. Given a user query and a list of tools, select the most appropriate tool.\n",
      "\n",
      "Query: \"What colors are available for AeroFlow?\"\n",
      "\n",
      "Available Tools:\n",
      "0. AeroFlow_specifications\n",
      "   Description: Use this tool for questions about AeroFlow vehicle specifications, including: design details, features, technology components, maintenance procedures, warranty information, performance metrics, and technical specifications. This covers all AeroFlow-related documentation.\n",
      "\n",
      "1. EcoSprint_specifications\n",
      "   Description: Use this tool for questions about EcoSprint vehicle specifications, including: design details, features, technology components, maintenance procedures, warranty information, performance metrics, and technical specifications. This covers all EcoSprint-related documentation.\n",
      "\n",
      "Select the most appropriate tool and explain your reasoning.\n",
      "\n",
      "\n",
      " LLM REASONING OUTPUT:\n",
      "------------------------------\n",
      "\n",
      "    The query asks about \"colors available for AeroFlow\", which specifically mentions AeroFlow.\n",
      "\n",
      "    Tool 0 (AeroFlow_specifications) is designed for AeroFlow-related questions and includes\n",
      "    \"design details\" and \"features\" in its description. Colors would fall under design details.\n",
      "\n",
      "    Tool 1 (EcoSprint_specifications) is for EcoSprint-related questions, which doesn't match\n",
      "    this query about AeroFlow.\n",
      "\n",
      "    Therefore, I select Tool 0.\n",
      "    \n",
      "\n",
      " KEY FACTORS IN ROUTING DECISIONS\n",
      "==================================================\n",
      "Factor               Description                              Influence      \n",
      "---------------------------------------------------------------------------\n",
      "Exact Name Match     Query contains 'AeroFlow' or 'EcoSprint'  Very High    \n",
      "Keyword Relevance    Technical terms match tool descriptions   High         \n",
      "Context Clues        Related terms suggest specific domain     Medium       \n",
      "Tool Descriptions    How well query aligns with tool purpose   Medium       \n",
      "LLM Training         Model's understanding of relationships    Background   \n",
      "\n",
      " Pro Tips for Better Routing:\n",
      " Use specific vehicle names in your queries\n",
      " Include relevant technical terms\n",
      " Be specific rather than generic\n",
      " Test edge cases to understand behavior\n",
      "\n",
      " To test with your actual router:\n",
      "   test_router_with_explanation(\"What colors are available for AeroFlow?\")\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T04:54:27.997719Z",
     "start_time": "2025-06-19T04:54:17.967502Z"
    }
   },
   "cell_type": "code",
   "source": "test_router_with_explanation(\"What colors are available for AeroFlow?\")",
   "id": "2417ab645a109725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TESTING ROUTER DECISION\n",
      "==================================================\n",
      "Query: 'What colors are available for AeroFlow?'\n",
      "\n",
      " Router is thinking...\n",
      " LLM Reasoning Process:\n",
      "------------------------------\n",
      " \u001B[1;3;38;5;200mSelecting query engine 0: The question asks about AeroFlow vehicle specifications, which is covered in option 1. The color availability falls under the 'design details' or 'features' category of a vehicle specification..\n",
      "   \u001B[0m\n",
      "\n",
      " Final Response:\n",
      "   Length: 90 characters\n",
      "   Preview:  The AeroFlow is available in colors such as Coastal Blue, Sunset Orange, and Pearl White.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response=' The AeroFlow is available in colors such as Coastal Blue, Sunset Orange, and Pearl White.', source_nodes=[NodeWithScore(node=TextNode(id_='96adfe61-c901-4161-aa79-9372d5c4a8bf', embedding=None, metadata={'page_label': '1', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='8f494123-5c9a-421f-84a4-9ea486e54dbc', node_type='4', metadata={'page_label': '1', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}, hash='388f5137813ff2f7aa44339469ac6a8b72f2e2f2bc296e442525a741b2ad97a7')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='AeroFlow\\nDetailed\\nSpecification\\nDocument\\n1.\\nOverview\\n\\nAeroFlow\\nis\\nthe\\nideal\\nfamily\\nelectric\\nvehicle,\\nbalancing\\nspace,\\ncomfort,\\nand\\nefficiency.\\nDesigned\\nwith\\nfamily\\nneeds\\nin\\nmind,\\nit\\noffers\\na\\nsafe,\\nspacious,\\nand\\nenvironmentally\\nfriendly\\noption\\nfor\\neveryday\\nfamily\\nlife\\nand\\nleisure.\\n2.\\nDesign\\nSpecifications\\n\\nExterior\\nDesign:\\nFeatures\\na\\nsleek,\\nmodern\\ndesign\\nwith\\na\\nspacious\\ninterior\\nlayout.\\nThe\\nAeroFlow\\nis\\navailable\\nin\\ncolors\\nsuch\\nas\\nCoastal\\nBlue,\\nSunset\\nOrange,\\nand\\nPearl\\nWhite.\\n\\nInterior\\nDesign:\\nBoasts\\na\\nversatile\\nand\\nroomy\\ninterior\\nwith\\nthree\\nrows\\nof\\nseating,\\naccommodating\\nup\\nto\\nseven\\npassengers.\\nIncludes\\nchild-friendly\\nmaterials,\\nample\\nstorage\\nspace,\\nand\\neasy\\naccess\\nto\\nall\\nseats.\\n3.\\nPerformance\\nSpecifications\\n\\nEngine\\nand\\nMotor:\\nSingle\\nelectric\\nmotor\\noptimized\\nfor\\nefficiency\\nand\\nreliability,\\nproviding\\na\\nsmooth\\nand\\nquiet\\ndriving\\nexperience.\\n\\nBattery\\nand\\nRange:\\nEquipped\\nwith\\na\\n60\\nkWh\\nbattery,\\nit\\nhas\\na\\nrange\\nof\\napproximately\\n230\\nmiles\\nper\\ncharge,\\nsuitable\\nfor\\ndaily\\ncommutes\\nand\\nfamily\\ntrips.\\n\\nAcceleration\\nand\\nTop\\nSpeed:\\nPrioritizing\\nsafety\\nand\\ncomfort\\nover\\nspeed,\\nit\\naccelerates\\nfrom\\n0\\nto\\n60\\nmph\\nin\\na\\ncomfortable\\n8\\nseconds,\\nwith\\na\\nfamily-friendly\\ntop\\nspeed.\\n4.\\nTechnology\\nand\\nFeatures\\n\\nInfotainment\\nSystem:\\nFeatures\\nan\\nintuitive\\n13-inch\\ntouchscreen\\ninfotainment\\nsystem\\nwith\\nvoice\\ncommands,\\ndedicated\\nchild\\nentertainment\\noptions,\\nand\\nmultiple\\nconnectivity\\nports.\\n\\nDriver\\nAssistance\\nSystems:\\nIncludes\\nadvanced\\nsafety\\nfeatures\\nlike\\nautomatic\\nemergency\\nbraking,\\nblind-spot\\nmonitoring,\\nand\\nadaptive\\ncruise\\ncontrol\\ntailored\\nfor\\nfamily\\nsafety.\\n\\nConnectivity:\\nComplete\\nwith\\nin-car\\nWi-Fi,\\nreal-time\\ntraffic\\nupdates,\\nand\\nremote\\nvehicle\\nmonitoring\\nand\\ncontrol\\nvia\\na\\nsmartphone\\napp.\\n5.\\nSafety\\nand\\nSecurity\\n\\nSafety\\nFeatures:\\nReinforced\\nframe\\nfor\\nenhanced\\nsafety,\\ncomplete\\nwith\\nadvanced\\nairbag\\nsystems\\nand\\na\\nhigh\\nsafety\\nrating\\nin\\ncrash\\ntests.\\n\\nSecurity\\nFeatures:\\nFeatures\\nsuch\\nas\\nchild\\nsafety\\nlocks,\\ngeo-fencing,\\nand\\nspeed\\nalerts\\nfor\\nteen\\ndrivers.\\n6.\\nMaintenance\\nand\\nWarranty\\n\\nRegular\\nMaintenance:\\nDesigned\\nwith\\nlow\\nmaintenance\\nrequirements\\nin\\nmind,\\nit\\nincludes\\nan\\neasy-to-follow\\nservice\\nschedule.\\n\\nWarranty:\\nComes\\nwith\\na\\n7-year/70,000-mile\\ncomprehensive\\nwarranty\\nand\\nan\\n8-year/90,000-mile\\nbattery\\nwarranty.', mimetype='text/plain', start_char_idx=0, end_char_idx=2216, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5228922328341263), NodeWithScore(node=TextNode(id_='56d960a9-b185-4182-8f1d-d3e4b2e9a1b3', embedding=None, metadata={'page_label': '2', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f1d3ee46-c9e2-4489-aff1-5dbea079a372', node_type='4', metadata={'page_label': '2', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}, hash='7ef3342c6e44a9400555d34035d48d87ea04d844a40692e48800713ed06a6a18')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='7.\\nPricing\\nand\\nModels\\n\\nPricing\\nStructure:\\nStarts\\nat\\nan\\naccessible\\nprice\\npoint\\nof\\n$40,000,\\noffering\\nexcellent\\nvalue\\nfor\\na\\nfamily\\nvehicle.\\n\\nModel\\nVariants:\\nAvailable\\nin\\nBasic,\\nComfort,\\nand\\nLuxury\\neditions,\\nwith\\neach\\nstep\\nup\\nadding\\nmore\\nfeatures\\nand\\nconveniences.', mimetype='text/plain', start_char_idx=0, end_char_idx=262, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.43430351789923516)], metadata={'96adfe61-c901-4161-aa79-9372d5c4a8bf': {'page_label': '1', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}, '56d960a9-b185-4182-8f1d-d3e4b2e9a1b3': {'page_label': '2', 'file_name': 'AeroFlow_Specification_Document.pdf', 'file_path': 'AeroFlow_Specification_Document.pdf', 'file_type': 'application/pdf', 'file_size': 36333, 'creation_date': '2025-06-19', 'last_modified_date': '2025-06-19'}, 'selector_result': MultiSelection(selections=[SingleSelection(index=0, reason=\"The question asks about AeroFlow vehicle specifications, which is covered in option 1. The color availability falls under the 'design details' or 'features' category of a vehicle specification.\")])})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aedb46b444ff8a4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
